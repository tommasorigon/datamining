---
title: "Frequently Asked Questions"
subtitle: "Data Mining - CdL CLAMSES"
author: "[Tommaso Rigon]{.orange}"
institute: "_Universit√† degli Studi di Milano-Bicocca_"
execute:
  cache: false
filters: 
  - remove-pause.lua
format:
  revealjs:
    df-print: tibble
    auto-stretch: true
    center: true
    html-math-method: katex
    transition: none
    output-file: un_F_slides.html
    slide-number: true
    callout-appearance: minimal
    code-line-numbers: true
    theme: [default, ../template.css] # alternative themes (subset): default, night, dark
    embed-resources: false
    echo: false
    fig-dpi: 200
    # incremental: true  # Remove comment if you like incremental bullet points
    logo: img/logoB.png
    footer: "[Home page](https://tommasorigon.github.io/datamining)"
  html:
    html-math-method: katex
    echo: false
    callout-appearance: minimal
    theme: [cosmo, ../template.css]
    toc: true
    toc-title: Table of contents
    embed-resources: false
    code-line-numbers: true
    smooth-scroll: true
    code-fold: false
    code-summary: "Show the code"
    fig-dpi: 200
editor: 
  markdown: 
    wrap: 72
editor_options: 
  chunk_output_type: console
---

## [Homepage](../index.html)

```{r}
#| warning: false
#| echo: false
#| include: false
#| message: false
#| purl: false

knitr::purl("un_G.qmd", output = "../code/un_G.R", documentation = 0)
styler:::style_file("../code/un_G.R")
```

::: columns
::: {.column width="50%"}
![](img/russell.jpg){width="60%" fig-align="center"}

::: {style="font-size: 80%;"}
"*The whole problem with the world is that fools and fanatics are always so certain of themselves, and wiser people so full of doubts.*" 

[Bertrand Russell]{.grey}
:::
:::

::: {.column width="50%"}
- This is not a normal unit and has a more dynamic nature. 

- I will collect here [interesting]{.blue} questions made by students over the years.

- The questions are organized by topic, but some overlap will occur.

- Hopefully, this unit will form the basis of a [statistical culture]{.orange}. 

- Indeed, it is based on the knowledge of several statisticians. 
:::
:::

# The modeling process

## What to do when different estimators lead to dissimilar conclusions?

- Well, it happens all the time in applied statistics. It even occurs in Statistics I!

- For example, you might get slightly different values (or even opposite signs) when looking at the estimated regression coefficients $\hat{\beta}_\text{ols}$, $\hat{\beta}_\text{pcr}$, $\hat{\beta}_\text{ridge}$.

- In linear models, do not assume the OLS estimator is "better" just because it is [unbiased]{.blue}. Biased estimates are helpful if they lead to a (sufficiently high) [reduction of the variance]{.orange}.

- In any event, remember these are, indeed, [estimates]{.orange}! By definition, there will be some variability; therefore, the [discrepancies]{.blue} might be due to random [fluctuations]{.orange}.

- To choose among different estimates, we need a criterion (or a combination of criteria), such as the [predictive performance]{.blue}. However, the out-of-sample error is [not]{.orange} the only relevant aspect! 

- There might be other considerations to keep in mind, including the [interpretability]{.blue}, the [robustness]{.orange} of the method, and the [computational complexity]{.grey}.

- Whenever different estimates display some differences, try to see it as an [opportunity]{.blue} to [learn something from the data]{.orange}. What could be the reason for such a discrepancy? What tells us about the data we are analyzing?

## How to interpret a wrong model?

- First of all, by wrong, we mean "[biased]{.orange}." Therefore, being "wrong" could be an advantage [if]{.orange} the [focus]{.blue} is on [pure predictions]{.blue}.  

- We can often say something about the [association]{.orange} between the response variable and the covariates, i.e. we can still try to [interpret]{.blue} the results. 

- Finding association is appropriate even in the presence of biased estimates, do not be discouraged by this aspect. However, you must be aware that the fitted model is, at best, an [approximation of reality]{.orange} (especially the biased ones), therefore you need to be prudent in your conclusions.

- The specific [type of association]{.blue} reflects the [assumptions]{.blue} implied by the chosen model. For example, linear models capture the [linear part]{.orange} of the unknown and possibly more complex relationship $f(x)$, but they cannot capture interactions (unless manually included). 

- At the very least, we can often say something about the main factors affecting the predictions. 

- Obviously, we must be [very careful]{.orange} before making any [causal statement]{.orange}. Remember that association $\neq$ causation even when the model is well-specified.

- Do not forget that the estimated effects should be interpreted as "*ceteris paribus*"! This means that the association between a variable and the response is often expressed conditionally on the other variables' effect. 

<!-- ## What is the difference between an algorithm and a model? -->

<!-- ::: columns -->
<!-- ::: {.column width="50%"} -->
<!-- - [Model]{.blue}: a simplified *mathematical* representation of reality. -->

<!-- - [Algorithm]{.blue}: a step-by-step procedure that is useful to obtain the unknown parts of a model. -->
<!-- ::: -->

<!-- ::: {.column width="50%"} -->
<!-- [Example]{.orange}: linear models, neural networks, support vector machine, trees. -->

<!-- [Example]{.orange}: gradient descent, Newton-Raphson, pathwise coordinate descent, LAR. -->
<!-- ::: -->
<!-- ::: -->

## Why do we care about simple models?

- Simple models are helpful to [explain]{.orange} reality, not just to make predictions.

- Simple models $\neq$ linear models. A tree with a few splits is indeed "simple." Some might say that parametric models relying on well-chosen assumptions are simple, but it depends. 

- Simple models tend to be more [robust]{.orange}, i.e., less affected by contamination and changes in the data generative process.

- Besides, the [understanding]{.blue} gained by fitting simple models is precious for estimating the more complex ones because it guides the next steps. 

- The modelling process is [iterative]{.blue} and [not a collection of independent]{.orange} and [separate approaches]{.orange}. You fit a model, check the results, and adjust your strategy. 

- Another practical concern is that senior statisticians know hundreds of different techniques. When all these ingredients are combined, they generate thousands, if not millions, of competing estimates. Hence, it becomes impossible to "use them all and pick the best performer." You need guidance to find the final answer. 

## What if simple models do not work well?

...for example, what to do when simple models do not predict well?

- In that case, of course, it is time to move on and try something more sophisticated. This occurs often in practice; not every case study can be solved with simple tools.

- However, you [should not]{.orange} fit a sophisticated model without trying the simple ones first. In other terms, I would fit a [deep neural network]{.blue} only after [everything else has failed]{.orange}, as a last resort.

- The statement "*data are complicated, therefore I need a complex model*" is probably the result of [hype/over-excitement]{.orange} for the new shiny machine learning tool. 

- Especially when data are complex, you should first check whether a simple solution exists. Sometimes this is actually the case, because "simple" models tend to high low variance. 

- A skilled statistician is not somebody who runs thousands of sophisticated models seeking for the one with the lowest error. A skilled statistician is more like an [artisan]{.blue}, who uses her/his tools [when needed]{.orange} and with [intelligence]{.orange}, obtaining accurate predictions because she/he has a good understanding of the data, not as a result of a blind trial and error. 

- Finally, even when it turns out that a complex model improves the predictive performance, always ask yourself: ["Is it worth it?"]{.orange} The answer is often [context-dependent]{.blue}. 

- Once again, there might be other considerations to keep in mind ([interpretability]{.blue}, [robustness]{.orange}, [computational complexity]{.grey}). 
