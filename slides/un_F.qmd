---
title: "Additive models"
subtitle: "Data Mining - CdL CLAMSES"
author: "[Tommaso Rigon]{.orange}"
institute: "_Universit√† degli Studi di Milano-Bicocca_"
execute:
  cache: false
filters: 
  - remove-pause.lua
format:
  revealjs:
    df-print: tibble
    auto-stretch: true
    center: true
    html-math-method: katex
    transition: none
    output-file: un_F_slides.html
    slide-number: true
    callout-appearance: minimal
    code-line-numbers: true
    theme: [default, ../template.css] # alternative themes (subset): default, night, dark
    embed-resources: false
    echo: false
    fig-dpi: 200
    # incremental: true  # Remove comment if you like incremental bullet points
    logo: img/logoB.png
    footer: "[Home page](https://tommasorigon.github.io/datamining)"
  html:
    html-math-method: katex
    echo: false
    callout-appearance: minimal
    theme: [cosmo, ../template.css]
    toc: true
    toc-title: Table of contents
    embed-resources: false
    code-line-numbers: true
    smooth-scroll: true
    code-fold: false
    code-summary: "Show the code"
    fig-dpi: 200
editor: 
  markdown: 
    wrap: 72
editor_options: 
  chunk_output_type: console
---

## [Homepage](../index.html)

```{r}
#| warning: false
#| echo: false
#| include: false
#| message: false
#| purl: false

knitr::purl("un_F.qmd", output = "../code/un_F.R")
styler:::style_file("../code/un_F.R")
```

::: columns
::: {.column width="35%"}
![](img/reef.jpg){width=60% fig-align="center"} 


::: {style="font-size: 90%;"}

:::


:::

::: {.column width="65%"}

-   In this unit we will cover the following [topics]{.orange}:

    - Generalized additive models (GAMs)
    - Multivariate Adaptive Regression Splines (MARS)

- We have seen that [fully nonparametric]{.blue} methods are plagued by the [curse of dimensionality]{.orange}.

- GAMs and MARS are [semi-parametric]{.blue} approaches that keep the model complexity under control so that: 
  - they are more flexible than linear models; 
  - but they are not hugely impacted by the curse of dimensionality.
    
- The running example is about [trawl data]{.orange} from the [Great Barrier Reef]{.blue}.
:::
:::

## The `trawl` dataset

::: incremental

- We consider the `trawl` dataset, refer to a survey of the fauna on the sea bed lying between the coast of northern Queensland and the Great Barrier Reef. 

- The sampling region covered a zone which was closed to commercial fishing, as well as neighboring zones where fishing was permitted.

- We want to [predict]{.blue} the [catch score]{.orange}, as a function of several covariates: 
  - number of hits/runs/walks/assists/errors in 1986 and during the whole career;
  - number of years in the major leagues;
  - The league/division of the player at the end of 1986;
  - ...and many others.
  
asd

:::

## A `glimpse` of the `trawl` dataset

```{r}
#| message: false
rm(list = ls())
library(ggplot2)
library(ggthemes)
library(sm)

data(trawl)
dplyr::glimpse(trawl)
```


```{r}
# Data splitting
set.seed(1234)
id_train <- sample(1:nrow(trawl), size = floor(0.5 * nrow(trawl)), replace = FALSE)
id_test <- setdiff(1:nrow(trawl), id_train)
trawl_train <- trawl[id_train, ]
trawl_test <- trawl[id_test, ]
```

## The `trawl` dataset

<div class="flourish-embed flourish-map" data-src="visualisation/15070357"><script src="https://public.flourish.studio/resources/embed.js"></script></div>

## A linear model

- In the first place, we split the dataset into [training]{.blue} and [test]{.orange} set, so that the validity of our approach

- 

<!-- ## Best subset selection -->

<!-- ```{r} -->
<!-- #| fig-width: 12 -->
<!-- #| fig-height: 6 -->
<!-- #| fig-align: center -->
<!-- library(leaps) -->
<!-- fit.bests <- regsubsets(Score1 ~ Zone + Year + Latitude + Longitude + Depth, data = trawl_train, nvmax = 5) -->
<!-- summary.bests <- summary(fit.bests) -->

<!-- par(mfrow = c(1, 2)) -->
<!-- plot(summary.bests$cp, xlab = "Number of covariates", ylab = "Mallow's Cp", type = "b", pch = 16) -->
<!-- plot(fit.bests, scale = "Cp") -->
<!-- ``` -->

<!-- ## The selected linear model -->

<!-- ```{r} -->
<!-- #| output: false -->
<!-- library(broom) -->
<!-- m_linear <- lm(logSalary ~ AtBat + Hits + CAtBat + CHits + CHmRUn+ Division, data = Hitters_train) -->
<!-- knitr::kable(tidy(summary(m_linear)), digits = 3) -->
<!-- ``` -->

<!-- |term        | estimate| std.error| statistic| p.value| -->
<!-- |:-----------|--------:|---------:|---------:|-------:| -->
<!-- |`(Intercept)` |    4.493|     0.177|    25.344|   0.000| -->
<!-- |`Hits`        |    0.004|     0.002|     2.255|   0.025| -->
<!-- |`Walks`       |    0.011|     0.003|     3.255|   0.001| -->
<!-- |`Years`       |    0.046|     0.022|     2.112|   0.036| -->
<!-- |`CRuns`       |    0.002|     0.001|     3.562|   0.000| -->
<!-- |`CWalks`      |   -0.001|     0.001|    -2.204|   0.029| -->
<!-- |`League_N`     |    0.173|     0.088|     1.959|   0.052| -->
<!-- |`Division_W`   |   -0.189|     0.087|    -2.165|   0.032| -->
<!-- |`Errors`      |   -0.012|     0.007|    -1.689|   0.093| -->

<!-- ## Comments and cricism to linear models -->

<!-- ## Scatterplot with `loess` estimate -->

<!-- ```{r} -->
<!-- #| fig-width: 7.8 -->
<!-- #| fig-height: 4 -->
<!-- #| fig-align: center -->
<!-- #| message: false -->
<!-- ggplot(data = Hitters_train, aes(x = Years, y = logSalary)) + -->
<!--   geom_point(size = 0.7) + -->
<!--   geom_smooth(se = FALSE, span = 1, col = "#1170aa") + -->
<!--   theme_minimal() + -->
<!--   xlab("Number of years in the major leagues (Years)") + -->
<!--   ylab("log(Salary)") -->
<!-- ``` -->


<!-- # Generalized additive models (GAM) -->

<!-- ## The ANOVA decomposition of a function -->

<!-- ## Generalized additive models (GAM) -->

<!-- ## The backfitting algorithm I -->

<!-- ## The backfitting algorithm II -->

<!-- ## Local scoring for additive logistic regression -->

<!-- ## GAM using penalized splines -->

<!-- ## GAM using penalized splines -->

<!-- ## Additive models -->

<!-- ```{r} -->
<!-- library(mgcv) -->
<!-- m_gam <- gam(logSalary ~ s(AtBat) + s(Hits) + s(HmRun) + s(Runs) + s(RBI) + s(Walks) + s(Years) + s(CAtBat) + s(CHits) + s(CHmRun) + s(CRuns) + s(CRBI) + s(CWalks) + League + Division + s(PutOuts) + s(Assists) + s(Errors) + NewLeague, data = Hitters_train, select = FALSE) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- summary(m_gam) -->
<!-- ``` -->

<!-- ## Variable selection -->

<!-- ```{r} -->
<!-- m_gam_selected <- gam(logSalary ~ s(AtBat) + s(Hits) + s(HmRun) + s(Runs) + s(RBI) + s(Walks) + s(Years) + s(CAtBat) + s(CHits) + s(CHmRun) + s(CRuns) + s(CRBI) + s(CWalks) + League + Division + s(PutOuts) + s(Assists) + s(Errors) + NewLeague, -->
<!--   data = Hitters_train, select = TRUE -->
<!-- ) -->

<!-- summary(m_gam_selected) -->
<!-- ``` -->

<!-- ## Partial effect (`Years`) -->

<!-- ```{r} -->
<!-- #| fig-width: 7.8 -->
<!-- #| fig-height: 4 -->
<!-- #| fig-align: center -->
<!-- #| message: false -->
<!-- library(gratia) -->
<!-- data_plot <- smooth_estimates(m_gam_selected, smooth = "s(Years)") -->

<!-- ggplot(data = data_plot, aes(x = Years, y = est)) + -->
<!--   geom_line(linewidth = 1, col = "#1170aa") + -->
<!--   geom_point(data = add_partial_residuals(m_gam_selected, data = Hitters_train), aes(x = Years, y = `s(Years)`), size = 0.7) + -->
<!--   theme_minimal() + -->
<!--   scale_color_tableau(palette = "Color Blind") + -->
<!--   xlab("Number of years in the major leagues (Years)") + -->
<!--   ylab("Partial effect") -->
<!-- ``` -->

<!-- ## -->

<!-- ```{r} -->
<!-- #| fig-width: 7.8 -->
<!-- #| fig-height: 4 -->
<!-- #| fig-align: center -->
<!-- #| message: false -->
<!-- data_plot <- smooth_estimates(m_gam_selected, smooth = "s(CHits)") -->

<!-- ggplot(data = data_plot, aes(x = CHits, y = est)) + -->
<!--   geom_line(linewidth = 1, col = "#1170aa") + -->
<!--   geom_point(data = add_partial_residuals(m_gam_selected, data = Hitters_train), aes(x = CHits, y = `s(CHits)`), size = 0.7) + -->
<!--   theme_minimal() + -->
<!--   scale_color_tableau(palette = "Color Blind") + -->
<!--   xlab("Number of years in the major leagues (Years)") + -->
<!--   ylab("Partial effect") -->
<!-- ``` -->


<!-- ## Pros and cons of generalized additive models (GAMs) -->

<!-- ::: callout-tip -->
<!-- #### Pros -->

<!-- -   asd -->
<!-- ::: -->

<!-- . . . -->

<!-- ::: callout-warning -->
<!-- #### Cons -->

<!-- - asd -->
<!-- ::: -->


<!-- # MARS -->

<!-- ## MARS -->

<!-- ##  -->

<!-- ```{r} -->
<!-- library(earth) -->
<!-- fit_mars_deg1 <- earth(logSalary ~ ., data = Hitters_train, degree = 1, pmethod="cv", nfold = 10) -->
<!-- summary(fit_mars_deg1, style = "pmax") -->
<!-- plot(evimp(fit_mars_deg1)) -->
<!-- plotmo(fit_mars_deg1) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- fit_mars_deg2 <- earth(logSalary ~ ., data = Hitters_train, degree = 2, pmethod="cv", nfold = 10) -->
<!-- summary(fit_mars_deg2, style = "pmax") -->
<!-- plot(evimp(fit_mars_deg2)) -->
<!-- plotmo(fit_mars_deg2) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- library(pdp) -->
<!-- earth_partial <- partial(fit_mars_deg2, pred.var = c("Years", "CHits"), grid.resolution = 40) -->
<!-- autoplot(earth_partial) + theme_light() -->
<!-- ``` -->

<!-- ## The `Hitters` dataset -->

<!-- ```{r} -->
<!-- library(pdp) -->
<!-- gam_partial <- partial(m_gam_selected, pred.var = c("Years", "CHits"), grid.resolution = 40) -->
<!-- autoplot(gam_partial) + theme_light() -->
<!-- ``` -->

<!-- ## Final results -->

<!-- ```{r} -->
<!-- y_test <- exp(Hitters_test$logSalary) -->

<!-- y_null <- exp(mean(Hitters_train$logSalary)) -->
<!-- y_hat_linear <- exp(predict(m_linear, newdata = Hitters_test)) -->
<!-- y_hat_gam <- exp(predict(m_gam, newdata = Hitters_test)) -->
<!-- y_hat_gam_selected <- exp(predict(m_gam_selected, newdata = Hitters_test)) -->
<!-- y_mars_deg1 <- exp(predict(fit_mars_deg1, newdata = Hitters_test)) -->
<!-- y_mars_deg2 <- exp(predict(fit_mars_deg2, newdata = Hitters_test)) -->

<!-- tab_results <-rbind(c( -->
<!--   mean(abs(y_test - y_null)), -->
<!--   mean(abs(y_test - y_hat_linear)), -->
<!--   mean(abs(y_test - y_hat_gam)), -->
<!--   mean(abs(y_test - y_hat_gam_selected)), -->
<!--   mean(abs(y_test - y_mars_deg1)), -->
<!--   mean(abs(y_test - y_mars_deg2))), -->
<!--   sqrt(c(mean(abs(y_test - y_null)^2), -->
<!--   mean(abs(y_test - y_hat_linear)^2), -->
<!--   mean(abs(y_test - y_hat_gam)^2), -->
<!--   mean(abs(y_test - y_hat_gam_selected)^2), -->
<!--   mean(abs(y_test - y_mars_deg1)^2), -->
<!--   mean(abs(y_test - y_mars_deg2)^2)))) -->
<!-- colnames(tab_results) <- c("Null model", "Best subset", "GAM", "GAM (selected)", "MARS (degree 1)", "MARS (degree 2)") -->
<!-- rownames(tab_results) <- c("Test MAE", "Test RMSE") -->
<!-- knitr::kable(tab_results, digits = 3) -->
<!-- ``` -->




<!-- ## References -->

<!-- -  -->
