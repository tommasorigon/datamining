<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tommaso Rigon">

<title>Additive models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="un_F_files/libs/clipboard/clipboard.min.js"></script>
<script src="un_F_files/libs/quarto-html/quarto.js"></script>
<script src="un_F_files/libs/quarto-html/popper.min.js"></script>
<script src="un_F_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="un_F_files/libs/quarto-html/anchor.min.js"></script>
<link href="un_F_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="un_F_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="un_F_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="un_F_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="un_F_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<style>html{ scroll-behavior: smooth; }</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#homepage" id="toc-homepage" class="nav-link active" data-scroll-target="#homepage">Homepage</a></li>
  <li><a href="#the-trawl-dataset" id="toc-the-trawl-dataset" class="nav-link" data-scroll-target="#the-trawl-dataset">The <code>trawl</code> dataset</a></li>
  <li><a href="#the-trawl-dataset-1" id="toc-the-trawl-dataset-1" class="nav-link" data-scroll-target="#the-trawl-dataset-1">The <code>trawl</code> dataset</a></li>
  <li><a href="#getting-started-linear-models" id="toc-getting-started-linear-models" class="nav-link" data-scroll-target="#getting-started-linear-models">Getting started: linear models</a></li>
  <li><a href="#scatterplot-with-loess-estimate" id="toc-scatterplot-with-loess-estimate" class="nav-link" data-scroll-target="#scatterplot-with-loess-estimate">Scatterplot with <code>loess</code> estimate</a></li>
  <li><a href="#comments-and-cricism-of-linear-models" id="toc-comments-and-cricism-of-linear-models" class="nav-link" data-scroll-target="#comments-and-cricism-of-linear-models">Comments and cricism of linear models</a></li>
  <li><a href="#generalized-additive-models-gam" id="toc-generalized-additive-models-gam" class="nav-link" data-scroll-target="#generalized-additive-models-gam">Generalized additive models (GAM)</a>
  <ul class="collapse">
  <li><a href="#the-anova-decomposition-of-a-function" id="toc-the-anova-decomposition-of-a-function" class="nav-link" data-scroll-target="#the-anova-decomposition-of-a-function">The ANOVA decomposition of a function</a></li>
  <li><a href="#generalized-additive-models-gam-1" id="toc-generalized-additive-models-gam-1" class="nav-link" data-scroll-target="#generalized-additive-models-gam-1">Generalized additive models (GAM)</a></li>
  <li><a href="#the-backfitting-algorithm-i" id="toc-the-backfitting-algorithm-i" class="nav-link" data-scroll-target="#the-backfitting-algorithm-i">The backfitting algorithm I</a></li>
  <li><a href="#the-backfitting-algorithm-ii" id="toc-the-backfitting-algorithm-ii" class="nav-link" data-scroll-target="#the-backfitting-algorithm-ii">The backfitting algorithm II</a></li>
  <li><a href="#the-backfitting-algorithm-regression" id="toc-the-backfitting-algorithm-regression" class="nav-link" data-scroll-target="#the-backfitting-algorithm-regression">The backfitting algorithm (regression)</a></li>
  <li><a href="#backfitting-comments-and-considerations" id="toc-backfitting-comments-and-considerations" class="nav-link" data-scroll-target="#backfitting-comments-and-considerations">Backfitting: comments and considerations</a></li>
  <li><a href="#the-backfitting-algorithm-classification" id="toc-the-backfitting-algorithm-classification" class="nav-link" data-scroll-target="#the-backfitting-algorithm-classification">The backfitting algorithm (classification)</a></li>
  <li><a href="#gam-using-penalized-splines" id="toc-gam-using-penalized-splines" class="nav-link" data-scroll-target="#gam-using-penalized-splines">GAM using penalized splines</a></li>
  <li><a href="#on-the-choice-of-smoothing-parameters" id="toc-on-the-choice-of-smoothing-parameters" class="nav-link" data-scroll-target="#on-the-choice-of-smoothing-parameters">On the choice of smoothing parameters</a></li>
  <li><a href="#gam-and-variable-selection" id="toc-gam-and-variable-selection" class="nav-link" data-scroll-target="#gam-and-variable-selection">GAM and variable selection</a></li>
  <li><a href="#gam-modeling-of-trawl-data" id="toc-gam-modeling-of-trawl-data" class="nav-link" data-scroll-target="#gam-modeling-of-trawl-data">GAM modeling of <code>trawl</code> data</a></li>
  <li><a href="#partial-effect-of-gams-longitude" id="toc-partial-effect-of-gams-longitude" class="nav-link" data-scroll-target="#partial-effect-of-gams-longitude">Partial effect of GAMs (<code>Longitude</code>)</a></li>
  <li><a href="#partial-effect-of-gams-latitude" id="toc-partial-effect-of-gams-latitude" class="nav-link" data-scroll-target="#partial-effect-of-gams-latitude">Partial effect of GAMs (<code>Latitude</code>)</a></li>
  <li><a href="#partial-effect-of-gams-depth" id="toc-partial-effect-of-gams-depth" class="nav-link" data-scroll-target="#partial-effect-of-gams-depth">Partial effect of GAMs (<code>Depth</code>)</a></li>
  <li><a href="#comments-and-criticism" id="toc-comments-and-criticism" class="nav-link" data-scroll-target="#comments-and-criticism">Comments and criticism</a></li>
  <li><a href="#naïve-bayes-classifier-and-gams" id="toc-naïve-bayes-classifier-and-gams" class="nav-link" data-scroll-target="#naïve-bayes-classifier-and-gams">☠️ - Naïve Bayes classifier and GAMs</a></li>
  <li><a href="#the-mgcv-r-package" id="toc-the-mgcv-r-package" class="nav-link" data-scroll-target="#the-mgcv-r-package">☠️ - The <code>mgcv</code> <strong>R</strong> package</a></li>
  <li><a href="#pros-and-cons-of-generalized-additive-models-gams" id="toc-pros-and-cons-of-generalized-additive-models-gams" class="nav-link" data-scroll-target="#pros-and-cons-of-generalized-additive-models-gams">Pros and cons of generalized additive models (GAMs)</a></li>
  </ul></li>
  <li><a href="#mars" id="toc-mars" class="nav-link" data-scroll-target="#mars">MARS</a>
  <ul class="collapse">
  <li><a href="#mars-1" id="toc-mars-1" class="nav-link" data-scroll-target="#mars-1">MARS</a></li>
  <li><a href="#partial-plots" id="toc-partial-plots" class="nav-link" data-scroll-target="#partial-plots">Partial plots</a></li>
  <li><a href="#final-results" id="toc-final-results" class="nav-link" data-scroll-target="#final-results">Final results</a></li>
  <li><a href="#pros-and-cons-of-mars" id="toc-pros-and-cons-of-mars" class="nav-link" data-scroll-target="#pros-and-cons-of-mars">Pros and cons of MARS</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="un_F_slides.html"><i class="bi bi-file-slides"></i>RevealJS</a></li></ul></div></nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Additive models</h1>
<p class="subtitle lead">Data Mining - CdL CLAMSES</p>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author"><span class="orange">Tommaso Rigon</span> </p>
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <em>Università degli Studi di Milano-Bicocca</em>
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  

</header>

<section id="homepage" class="level2">
<h2 class="anchored" data-anchor-id="homepage"><a href="../index.html">Homepage</a></h2>
<div class="columns">
<div class="column" style="width:35%;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/reef.jpg" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
<div style="font-size: 90%;">
<p>The <a href="https://en.wikipedia.org/wiki/Great_Barrier_Reef">Great Barrier Reef</a></p>
</div>
</div><div class="column" style="width:65%;">
<ul>
<li><p>In this unit we will cover the following <span class="orange">topics</span>:</p>
<ul>
<li>Generalized additive models (GAMs)</li>
<li>Multivariate Adaptive Regression Splines (MARS)</li>
</ul></li>
<li><p>We have seen that <span class="blue">fully nonparametric</span> methods are plagued by the <span class="orange">curse of dimensionality</span>.</p></li>
<li><p>GAMs and MARS are <span class="blue">semi-parametric</span> approaches that keep the model complexity under control so that:</p>
<ul>
<li>they are more flexible than linear models;</li>
<li>they are not hugely impacted by the curse of dimensionality.</li>
</ul></li>
<li><p>The running example is about <span class="orange">trawl data</span> from the <span class="blue">Great Barrier Reef</span>.</p></li>
</ul>
</div>
</div>
</section>
<section id="the-trawl-dataset" class="level2">
<h2 class="anchored" data-anchor-id="the-trawl-dataset">The <code>trawl</code> dataset</h2>
<div class="incremental">
<ul class="incremental">
<li><p>We consider the <code>trawl</code> dataset, which refers to a <span class="blue">survey</span> of the <span class="blue">fauna</span> on the sea bed lying between the coast of northern Queensland and the <span class="orange">Great Barrier Reef</span>.</p></li>
<li><p>The <span class="blue">response</span> variable is <code>Score</code>, which is a standardized numeric quantity measuring the amount of fishes caught on a given location.</p></li>
<li><p>We want to <span class="blue">predict</span> the <span class="orange">catch score</span>, as a function of a few covariates:</p>
<ul class="incremental">
<li>the <code>Latitude</code> and <code>Longitude</code> of the sampling position. The longitude can be seen as a proxy of the distance from the coast in this specific experiment;</li>
<li>the <code>Depth</code> of the sea on the sampling position;</li>
<li>the <code>Zone</code> of the sampling region, either open or closed to <span class="blue">commercial fishing</span>;</li>
<li>the <code>Year</code> of the sampling, which can be either <code>1992</code> or <code>1993</code>.</li>
</ul></li>
<li><p>Having remove a few observations due to missingness, we split the data into <span class="blue">training</span> (119 obs.) and <span class="orange">test</span> set (30 obs.). The full <code>trawl</code> dataset is available in the <code>sm</code> R package.</p></li>
</ul>
</div>
</section>
<section id="the-trawl-dataset-1" class="level2">
<h2 class="anchored" data-anchor-id="the-trawl-dataset-1">The <code>trawl</code> dataset</h2>
<div class="flourish-embed flourish-map" data-src="visualisation/15070357">
<script src="https://public.flourish.studio/resources/embed.js"></script>
</div>
</section>
<section id="getting-started-linear-models" class="level2">
<h2 class="anchored" data-anchor-id="getting-started-linear-models">Getting started: linear models</h2>
<ul>
<li><p>Let begin our analysis by trying to predict the <code>Score</code> using a <span class="orange">linear model</span> of the form <span class="math display">
y_i = \beta_0 + \beta_1 x_{i1} + \cdots + \beta_px_{ip}, \qquad i=1,\dots,n,
</span></p></li>
<li><p>The above values correspond to the variables of the <code>trawl</code> dataset, so that <span class="math display">
\begin{aligned}
\texttt{Score}_i = \beta_0 &amp;+ \beta_1 \texttt{Latitude}_i + \beta_2 \texttt{Longitude}_i + \\
&amp;+ \beta_3\texttt{Depth}_i + \beta_4 I(\texttt{Zone}_i = \texttt{Closed}) + \beta_5 I(\texttt{Year}_i = \texttt{1993}).
\end{aligned}
</span></p></li>
<li><p>Such a model can be estimated using <span class="orange">ordinary least squares</span>, resulting in:</p></li>
</ul>
<div style="font-size: 75%;">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>(Intercept)</code></td>
<td style="text-align: right;">297.690</td>
<td style="text-align: right;">26.821</td>
<td style="text-align: right;">11.099</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>Latitude</code></td>
<td style="text-align: right;">0.256</td>
<td style="text-align: right;">0.222</td>
<td style="text-align: right;">1.151</td>
<td style="text-align: right;">0.252</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>Longitude</code></td>
<td style="text-align: right;">-2.054</td>
<td style="text-align: right;">0.187</td>
<td style="text-align: right;">-10.955</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>Depth</code></td>
<td style="text-align: right;">0.020</td>
<td style="text-align: right;">0.007</td>
<td style="text-align: right;">3.003</td>
<td style="text-align: right;">0.003</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>Zone_Closed</code></td>
<td style="text-align: right;">-0.116</td>
<td style="text-align: right;">0.102</td>
<td style="text-align: right;">-1.143</td>
<td style="text-align: right;">0.255</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>Year_1993</code></td>
<td style="text-align: right;">0.127</td>
<td style="text-align: right;">0.103</td>
<td style="text-align: right;">1.242</td>
<td style="text-align: right;">0.217</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="scatterplot-with-loess-estimate" class="level2">
<h2 class="anchored" data-anchor-id="scatterplot-with-loess-estimate">Scatterplot with <code>loess</code> estimate</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_F_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="1800"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="comments-and-cricism-of-linear-models" class="level2">
<h2 class="anchored" data-anchor-id="comments-and-cricism-of-linear-models">Comments and cricism of linear models</h2>
<ul>
<li>Is this a good model?</li>
</ul>
<ul>
<li>Granted that every model is just an approximation of reality, it is undeniable that there are some <span class="orange">problematic</span> aspects.</li>
</ul>
<ul>
<li><p>By simple graphical inspection, it seems that the relationship between <code>Score</code> and <code>Longitude</code> is <span class="orange">non-linear</span>.</p></li>
<li><p>Also, an <span class="blue">interaction effect</span> between <code>Year</code> and <code>Longitude</code> could be present.</p></li>
</ul>
<ul>
<li><p>These considerations support the idea that <span class="blue">nonparametric approach</span> might be more appropriate.</p></li>
<li><p>However, the number of covariates is <span class="math inline">p = 5</span> and therefore a fully nonparametric estimation would <span class="orange">not</span> be <span class="orange">feasible</span>, because of the curse of dimensionality.</p></li>
<li><p>We need a simplified modelling strategy, that accounts for non-linearities but at the same time is not fully flexible.</p></li>
</ul>
</section>
<section id="generalized-additive-models-gam" class="level1">
<h1>Generalized additive models (GAM)</h1>
<section id="the-anova-decomposition-of-a-function" class="level2">
<h2 class="anchored" data-anchor-id="the-anova-decomposition-of-a-function">The ANOVA decomposition of a function</h2>
<ul>
<li>We seek for an estimate of (a suitable transformation of) the <span class="blue">mean function</span>, namely <span class="math display">
g^{-1}\{\mathbb{E}(Y_i)\} = f(x_{i1},\dots,x_{ip}),
</span> where <span class="math inline">g^{-1}(\cdot)</span> is the so-called <span class="orange">link function</span>.</li>
</ul>
<ul>
<li>The <span class="orange">unknown</span> multivariate function <span class="math inline">f(\bm{x}) = f(x_1,\dots,x_p) : \mathbb{R}^p \rightarrow \mathbb{R}</span> is <span class="orange">too complex</span>. However, the following <span class="blue">decomposition</span> holds <span class="math display">
f(\bm{x}) = \beta_0 + \underbrace{\sum_{j=1}^p f_j(x_j)}_{\text{Main effect}} + \underbrace{\sum_{j=1}^p\sum_{k &lt; j}f_{jk}(x_j, x_k)}_{\text{Interaction effect}} + \underbrace{\sum_{j=1}^p\sum_{k &lt; j}\sum_{h &lt; k &lt; j}f_{jkh}(x_j, x_k, x_h)}_{\text{Higher order interaction}} + \cdots.
</span></li>
</ul>
<ul>
<li><p>By imposing <span class="blue">suitable constraints</span>, this decomposition can be made <span class="orange">unique</span>.</p></li>
<li><p>More importantly, this decomposition gives us an intuition on how to build non-linear models with a simplified structure.</p></li>
</ul>
</section>
<section id="generalized-additive-models-gam-1" class="level2">
<h2 class="anchored" data-anchor-id="generalized-additive-models-gam-1">Generalized additive models (GAM)</h2>
<ul>
<li>A <span class="blue">generalized additive model</span> (GAM) presumes a representation of the following type: <span class="math display">
f(\bm{x}_i) = \beta_0 + f_1(x_{i1}) + \cdots + f_p(x_{ip}) = \beta_0 + \sum_{j=1}^pf_j(x_{ij}), \qquad i=1,\dots,n,
</span> where <span class="math inline">f_1,\dots,f_p</span> are <span class="orange">smooth univariate</span> functions with a potentially non-linear behavior.</li>
</ul>
<ul>
<li><p>In GAMs we include only the <span class="blue">main effects</span> and we <span class="orange">exclude</span> the <span class="orange">interactions</span> terms.</p></li>
<li><p>Generalized linear models (GLMs) are a <span class="orange">special case</span> of GAMs, in which <span class="math inline">f_j(x_{ij}) = \beta_j x_{ij}</span>.</p></li>
</ul>
<ul>
<li>To avoid what is essentially a problem of <span class="blue">model identifiability</span>, it is necessary for the various <span class="math inline">f_j</span> to be centered around <span class="math inline">0</span>, that is <span class="math display">
\sum_{i=1}^n f_j(x_{ij}) = 0, \qquad j=1,\dots,p.
</span></li>
</ul>
</section>
<section id="the-backfitting-algorithm-i" class="level2">
<h2 class="anchored" data-anchor-id="the-backfitting-algorithm-i">The backfitting algorithm I</h2>
<ul>
<li>There exist several strategies for <span class="orange">estimating</span> the <span class="orange">unknown functions</span> <span class="math inline">f_1,\dots,f_p</span>. One of them, called <span class="blue">backfitting</span>, is particularly appealing because of its elegance and generality.</li>
</ul>
<ul>
<li><p>Suppose we model each <span class="math inline">f_j(x) = \sum_{m = 1}^{M_j}\beta_{mj} h_{mj}(x)</span> with a <span class="orange">basis expansion</span>, for example using <span class="blue">regression splines</span>.</p></li>
<li><p>In a <span class="orange">regression problem</span> we need to minimize, over the unknown <span class="math inline">\beta</span> parameters, the loss <span class="math display">
\sum_{i=1}^n\left\{y_i - \beta_0 - \sum_{j=1}^pf_j(x_{ij})\right\}^2
</span> subject to the constraint <span class="math inline">\sum_{i=1}^n f_j(x_{ij}) = 0</span>.</p></li>
</ul>
<ul>
<li><p>When <span class="math inline">f_j</span> are regression splines, the above loss can be <span class="orange">minimized</span> using <span class="orange">least squares</span>. The identifiability issue could be handled by removing the intercept term from each spline basis.</p></li>
<li><p>However, here we consider an <span class="orange">alternative</span> and <span class="blue">iterative</span> minimization method, which is similar to the coordinate descent algorithm we employed for the elastic-net.</p></li>
</ul>
</section>
<section id="the-backfitting-algorithm-ii" class="level2">
<h2 class="anchored" data-anchor-id="the-backfitting-algorithm-ii">The backfitting algorithm II</h2>
<ul>
<li>Now, let us re-arrange the term in the squared loss as follows: <span class="math display">
  \sum_{i=1}^n\left\{\textcolor{red}{y_i - \beta_0 - \sum_{k\neq j}f_k(x_{ik})} - f_j(x_{ij})\right\}^2,
</span> where the highlighted terms are sometimes called <span class="blue">partial residuals</span>.</li>
</ul>
<!-- - If all the functions but the $j$th were known, the estimation would reduce to a [univariate nonparametric smoothing]{.orange} of the $j$th covariate using the partial residuals as response. -->
<ul>
<li>Hence, we can repeatedly and iteratively fit a <span class="blue">univariate smoothing</span> model for <span class="math inline">f_j</span> using the <span class="orange">partial residuals</span> as <span class="orange">response</span>, keeping fixed the value of the other functions <span class="math inline">f_k</span>, for <span class="math inline">k \neq j</span>.</li>
</ul>
<ul>
<li>This algorithm produces the same fit of least squares when <span class="math inline">f_j</span> are regression splines, but the idea is appealing because it can be used with any <span class="blue">generic smoothers</span> <span class="math inline">\mathcal{S}_j</span>.</li>
</ul>
<ul>
<li>Finally, note that under the constraint <span class="math inline">\sum_{i=1}^n f_j(x_{ij}) = 0</span> the least square estimate for the <span class="orange">intercept</span> term is <span class="math inline">\hat{\beta}_0 = \bar{y}</span>, i.e.&nbsp;the arithmetic mean.</li>
</ul>
</section>
<section id="the-backfitting-algorithm-regression" class="level2">
<h2 class="anchored" data-anchor-id="the-backfitting-algorithm-regression">The backfitting algorithm (regression)</h2>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The backfitting algorithm for additive regression models
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><p>Initialize <span class="math inline">\hat{\beta}_0 = \bar{y}</span> and set <span class="math inline">f_j(x_j) = 0</span>, for <span class="math inline">j=1,\dots,p</span>.</p></li>
<li><p>Cycle <span class="math inline">j =1,\dots,p</span>, <span class="math inline">j =1,\dots,p</span>, <span class="math inline">\dots</span>, until <span class="orange">convergence</span>:</p>
<ol type="i">
<li><p>Update the <span class="math inline">k</span>th function by smoothing via <span class="math inline">\mathcal{S}_j</span> the <span class="blue">partial residuals</span>, so that <span class="math display">
\hat{f}_j(x) \leftarrow \mathcal{S}_j\left[\left\{x_{ij}, y_i - \hat{\beta}_0 - \sum_{k \neq j} \hat{f}_k(x_{ik})\right\}_{i=1}^n\right].
</span></p></li>
<li><p>Center the function by subtracting its mean <span class="math display">
\hat{f}_j(x) \leftarrow \hat{f}_j(x) - \frac{1}{n}\sum_{i=1}^n\hat{f}_j(x_{ij}).
</span></p></li>
</ol></li>
</ol>
</div>
</div>
</section>
<section id="backfitting-comments-and-considerations" class="level2">
<h2 class="anchored" data-anchor-id="backfitting-comments-and-considerations">Backfitting: comments and considerations</h2>
<ul>
<li><p>The backfitting algorithm, when <span class="math inline">f_j</span> are modeled as <span class="blue">regression splines</span>, is known as “Gauss-Seidel”. The <span class="orange">convergence</span> is <span class="orange">guaranteed</span> under standard conditions.</p></li>
<li><p>Interestingly, even when <span class="math inline">\mathcal{S}_j</span> are <span class="blue">smoothing splines</span> the <span class="orange">convergence</span> of backfitting is <span class="orange">guaranteed</span>; the proof for this statement is less straightforward.</p></li>
</ul>
<ul>
<li>In general, however, there is no theoretical guarantee that the algorithm will ever converge, even though the practical experience suggest that this is <span class="orange">not</span> a <span class="orange">big concern</span>.</li>
</ul>
<ul>
<li>When <span class="math inline">\mathcal{S}_j</span> is a <span class="orange">linear smoother</span> with smoothing matrix <span class="math inline">\bm{S}_j</span>, then by analogy with the previous unit we can define the <span class="blue">effective degrees of freedom</span> of <span class="math inline">\hat{f}_j</span> as <span class="math display">
\text{df}_j = \text{tr}(\bm{S}_j).
</span> The number of degrees of the whole model therefore is <span class="math inline">\text{df} = 1 + \sum_{j=1}^p \text{df}_j</span>.</li>
</ul>
<ul>
<li>A variant of backfitting for classification problems is available. Once again, relying on <span class="orange">quadratic approximations</span> of the log-likelihood allows for a generalization to GLMs.</li>
</ul>
</section>
<section id="the-backfitting-algorithm-classification" class="level2">
<h2 class="anchored" data-anchor-id="the-backfitting-algorithm-classification">The backfitting algorithm (classification)</h2>
<div class="callout callout-style-simple callout-note no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Local scoring algorithm for additive logistic regression
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><p>Initialize <span class="math inline">\hat{\beta}_0 = \text{logit}(\bar{y})</span> and set <span class="math inline">f_j(x_j) = 0</span>, for <span class="math inline">j=1,\dots,p</span>.</p></li>
<li><p>Iterate <span class="orange">until convergence</span>:</p>
<ol type="i">
<li><p>Define the quantities <span class="math inline">\hat{\eta}_i = \hat{\beta}_0 + \sum_{j=1}^p\hat{f}_j(x_{ij})</span> and <span class="math inline">\hat{\pi}_i = \{1 + \exp(-\hat{\eta}_i)\}^{-1}</span>.</p></li>
<li><p>Construct the <span class="orange">working response</span> <span class="math display">
z_i = \hat{\eta}_i + \frac{y_i - \hat{\pi}_i}{\hat{\pi}_i(1 - \hat{\pi}_i)}, \qquad i=1,\dots,n.
</span></p></li>
<li><p>Construct the <span class="orange">weights</span> <span class="math inline">w_i = \hat{\pi}_i(1 - \hat{\pi}_i)</span>, for <span class="math inline">i=1,\dots,n</span>.</p></li>
<li><p>Use a <span class="blue">weighted backfitting</span> algorithm using the <span class="math inline">z_i</span> as responses, which produces a new set of estimates <span class="math inline">\hat{f}_1,\dots,\hat{f}_p</span>.</p></li>
</ol></li>
</ol>
</div>
</div>
</section>
<section id="gam-using-penalized-splines" class="level2">
<h2 class="anchored" data-anchor-id="gam-using-penalized-splines">GAM using penalized splines</h2>
<ul>
<li>A common special instance of GAM occurs when <span class="blue">smoothing splines</span> are employed. In the regression case, the <span class="orange">backfitting</span> algorithm implicitly minimizes the following <span class="orange">penalized loss</span> <span class="math display">
\mathscr{L}(f_1,\dots,f_p; \lambda) = \sum_{i=1}^n\left\{y_i - \beta_0 - \sum_{j=1}^pf_j(x_j)\right\}^2 + \sum_{j=1}^p\lambda_j \int_{a_j}^{b_j}\{f''_j(t)\}^2\mathrm{d}t,
</span> where <span class="math inline">\lambda = (\lambda_1,\dots,\lambda_p)</span> is a vector of <span class="blue">smoothing parameters</span>.</li>
</ul>
<ul>
<li><p>Each <span class="math inline">f_j(x;\beta)</span> is a <span class="orange">natural cubic spline</span>, therefore the penalized least squares criterion is <span class="math display">
\mathscr{L}(\beta; \lambda) = \sum_{i=1}^n\left\{y_i - \beta_0 - \sum_{j=1}^pf_j(x_j; \beta_j)\right\}^2 + \sum_{j=1}^p\lambda_j \beta_j^T\bm{\Omega}_j\beta_j,
</span> whose joint <span class="blue">minimization</span> over <span class="math inline">\beta</span> is available in closed form.</p></li>
<li><p>Hence, a <span class="orange">direct algorithm</span> that minimizes <span class="math inline">\mathscr{L}(\beta; \lambda)</span> is used instead of backfitting.</p></li>
</ul>
</section>
<section id="on-the-choice-of-smoothing-parameters" class="level2">
<h2 class="anchored" data-anchor-id="on-the-choice-of-smoothing-parameters">On the choice of smoothing parameters</h2>
<ul>
<li><p>In GAMs there are <span class="math inline">p</span> <span class="orange">smoothing parameters</span> <span class="math inline">\lambda_1,\dots,\lambda_p</span> that must be selected. We can proceed in the usual way, e.g.&nbsp;considering the <span class="blue">generalized cross-validation</span> criteria: <span class="math display">
\text{GCV}(\lambda_1,\dots,\lambda_p) = \frac{1}{n}\sum_{i=1}^n \left(\frac{y_i - \hat{y}_i}{1 - \text{df}/n}\right)^2.
</span></p></li>
<li><p>An alternative criterion in this context is the <span class="blue">REML</span> (Restricted Maximum Likelihood), which is the <span class="blue">marginal likelihood</span> of the corresponding <span class="orange">Bayesian model</span>.</p></li>
</ul>
<ul>
<li>It is <span class="orange">not possible</span> to construct a <span class="orange">grid</span> of values for all the combinations of smoothing parameters <span class="math inline">\lambda_1,\dots,\lambda_p</span>, because the number of terms increases exponentially in <span class="math inline">p</span>.</li>
</ul>
<ul>
<li><p>Hence, many software packages <span class="blue">numerically optimize</span> the <span class="math inline">\text{GCV}(\lambda_1,\dots,\lambda_p)</span>, or other information criteria, as a function of <span class="math inline">\lambda_1,\dots,\lambda_p</span>, using e.g. the Newton-Raphson method.</p></li>
<li><p>Such an approach is particularly convenient in combination with <span class="orange">smoothing splines</span>, because the <span class="orange">derivatives</span> needed for Newton’s method are available in closed form.</p></li>
</ul>
</section>
<section id="gam-and-variable-selection" class="level2">
<h2 class="anchored" data-anchor-id="gam-and-variable-selection">GAM and variable selection</h2>
<div class="incremental">
<ul class="incremental">
<li><p>When <span class="math inline">p</span> is large there is need to remove the potentially <span class="orange">irrelevant variables</span>. There exist several <span class="blue">variable selection</span> ideas for GAMs, but we will not cover the details here.</p></li>
<li><p><span class="blue">Option 1</span>. <span class="orange">Stepwise regression</span>. Perhaps the simplest method, although it is not as efficient as in linear models because we cannot exploit the same computational tricks.</p></li>
<li><p><span class="blue">Option 2</span>. <span class="orange">COSSO: Component Selection and Smoothing Operator</span> (Lin and Zhang, 2006). It’s an idea based on combining lasso-type penalties and GAMs.</p></li>
<li><p><span class="blue">Option 3</span>. <span class="orange">SpAM: Sparse Additive Models</span> (Ravikumar, Liu, Lafferty and Wasserman, 2009). Similar to the above, but it exploits a variation of the non-negative garrote.</p></li>
<li><p><span class="blue">Option 4</span>. <span class="orange">Double-penalty and shrinkage</span> (Marra and Wood, 2011). It acts on the penalty term of smoothing splines so that high-values of <span class="math inline">\lambda_1,\dots,\lambda_p</span> leads to constant functions.</p></li>
<li><p><span class="blue">Option X</span>. <span class="orange">Fancy name</span>. Yet another method for variable selection with GAMs.</p></li>
</ul>
</div>
</section>
<section id="gam-modeling-of-trawl-data" class="level2">
<h2 class="anchored" data-anchor-id="gam-modeling-of-trawl-data">GAM modeling of <code>trawl</code> data</h2>
<ul>
<li><p>Let us get back to the <code>trawl</code> data. A <span class="blue">specification</span> based on GAM could be<span class="math display">
  \begin{aligned}
  \texttt{Score}_i = \beta_0 &amp;+  f_1(\texttt{Longitude}_i)+ f_2(\texttt{Latitude}_i) + f_3(\texttt{Depth}_i) +\\
  &amp;+ \beta_1 I(\texttt{Zone}_i = \texttt{Closed}) + \beta_2 I(\texttt{Year}_i = \texttt{1993}).
  \end{aligned}
  </span></p></li>
<li><p>In GAMs the predictors are <span class="blue">not necessarily</span> modeled using <span class="blue">nonparametric</span> methods. Indeed, it is common to have a combination of smooth functions and linear terms.</p></li>
<li><p>Besides, it does <span class="orange">not make sense</span> to “smooth” a <span class="orange">dummy variable</span>.</p></li>
</ul>
<div style="font-size: 75%;">
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">df</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>(Intercept)</code></td>
<td style="text-align: right;">0.849</td>
<td style="text-align: right;">0.088</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>Zone_Closed</code></td>
<td style="text-align: right;">-0.075</td>
<td style="text-align: right;">0.099</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>Year_1993</code></td>
<td style="text-align: right;">0.149</td>
<td style="text-align: right;">0.093</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>s(Longitude)</code></td>
<td style="text-align: right;">-</td>
<td style="text-align: right;">-</td>
<td style="text-align: right;">4.694</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>s(Latitude)</code></td>
<td style="text-align: right;">-</td>
<td style="text-align: right;">-</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>s(Depth)</code></td>
<td style="text-align: right;">-</td>
<td style="text-align: right;">-</td>
<td style="text-align: right;">2.447</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="partial-effect-of-gams-longitude" class="level2">
<h2 class="anchored" data-anchor-id="partial-effect-of-gams-longitude">Partial effect of GAMs (<code>Longitude</code>)</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_F_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="1560"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="partial-effect-of-gams-latitude" class="level2">
<h2 class="anchored" data-anchor-id="partial-effect-of-gams-latitude">Partial effect of GAMs (<code>Latitude</code>)</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_F_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="1560"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="partial-effect-of-gams-depth" class="level2">
<h2 class="anchored" data-anchor-id="partial-effect-of-gams-depth">Partial effect of GAMs (<code>Depth</code>)</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_F_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid figure-img" width="1560"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="comments-and-criticism" class="level2">
<h2 class="anchored" data-anchor-id="comments-and-criticism">Comments and criticism</h2>
<ul>
<li>The fitted GAM model highlights some interesting aspects of the <code>trawl</code> data.</li>
</ul>
<ul>
<li><p>In the first place, it seems confirmed that the <code>Longitude</code> has a <span class="orange">marked non-linear</span> impact on the <span class="blue">catch score</span>, as the initial analysis was suggesting.</p></li>
<li><p>In particular, the catch score is high when the sampling location is close to the coast (but not too close!), and then it suddenly decreases.</p></li>
</ul>
<ul>
<li><p>The effective degrees of freedom of <code>Latitude</code> is <span class="math inline">\text{df}_2 = 1</span>, meaning that the estimated <span class="math inline">\hat{f}_2</span> <span class="blue">collapsed</span> to a <span class="blue">linear term</span>. The corresponding shrinkage parameter <span class="math inline">\lambda_2</span> is very high.</p></li>
<li><p>Overall, the effect due to the <code>Latitude</code> looks <span class="orange">small</span> or <span class="orange">not present</span> at all.</p></li>
</ul>
<ul>
<li>The <code>Depth</code> seems to have a <span class="orange">relevant effect</span> on the <code>Score</code>, but this is likely due to a few <span class="blue">leverage points</span> at the right extreme of the <code>Depth</code> range.</li>
</ul>
<ul>
<li>Finally, we note that both <code>Zone</code> and <code>Year</code> seem to have a minor effect.</li>
</ul>
</section>
<section id="naïve-bayes-classifier-and-gams" class="level2">
<h2 class="anchored" data-anchor-id="naïve-bayes-classifier-and-gams">☠️ - Naïve Bayes classifier and GAMs</h2>
<ul>
<li><p>The <span class="orange">naïve Bayes classifier</span> expresses the <span class="blue">binary</span> classification probability <span class="math inline">\text{pr}(y = 1 \mid \bm{x})</span> as <span class="math display">
\text{pr}(y = 1 \mid \bm{x}) = \frac{\pi_1 \prod_{j=1}^p p_{j1}(x_j)}{\pi_0\prod_{j=1}^p p_{j0}(x_j) + \pi_1\prod_{j=1}^p p_{j1}(x_j)} = \frac{\pi_1\prod_{j=1}^p p_{j1}(x_j)}{p(\bm{x})}.
</span></p></li>
<li><p>Hence, using class <span class="math inline">0</span> as a <span class="orange">baseline</span>, we can derive the following expression:<span class="math display">
\log\frac{\text{pr}(y = 1 \mid \bm{x})}{\text{pr}(y = 0 \mid \bm{x})} = \log\frac{\pi_1\prod_{j=1}^p p_{j1}(x_j)}{\pi_0\prod_{j=1}^p p_{j0}(x_j)} = \log\frac{\pi_1}{\pi_0} + \sum_{j=1}^p\log\frac{p_{j1}(x_j)}{p_{j0}(x_j)} = \beta_0 + \sum_{j=1}^pf_j(x_j).
</span></p></li>
</ul>
<ul>
<li><p>Therefore, although naïve Bayes and GAMs are fitted in a quite different way, there is a <span class="orange">tight connection</span> among the two methods.</p></li>
<li><p>Naïve Bayes has a <span class="blue">generalized additive model structure</span>. This also suggests that the “<span class="orange">additive assumption</span>” is linked to the notion of <span class="orange">independence</span> among the covariates.</p></li>
</ul>
</section>
<section id="the-mgcv-r-package" class="level2">
<h2 class="anchored" data-anchor-id="the-mgcv-r-package">☠️ - The <code>mgcv</code> <strong>R</strong> package</h2>
<div class="columns">
<div class="column" style="width:35%;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/iceberg.jpg" class="img-fluid figure-img" style="width:100.0%"></p>
</figure>
</div>
</div><div class="column" style="width:65%;">
<div class="incremental">
<ul class="incremental">
<li><p>GAMs were <span class="orange">invented</span> by Hastie and Tibshirani in 1986, including the backfitting algorithm.</p></li>
<li><p>Simon Wood (2003) described <span class="blue">thin-plate regression splines</span> and their estimation (no backfitting).</p></li>
<li><p>Simon Wood (2004, 2011) invented methods for estimating <span class="math inline">\lambda_1,\dots,\lambda_p</span> in an <span class="orange">efficient</span> and <span class="orange">stable</span> manner.</p></li>
<li><p>Marra and Wood (2011) discussed many methods for practical <span class="orange">variable selection</span> for GAMs.</p></li>
<li><p>For further details, there is a <span class="blue">recent and advanced book</span> by Simon Wood (2017) entitled “<em>Generalized Additive Models: An Introduction with R</em>”.</p></li>
<li><p>The <code>mgcv</code> package in <strong>R</strong> (by Simon Wood) implements everything mentioned here.</p></li>
</ul>
</div>
</div>
</div>
</section>
<section id="pros-and-cons-of-generalized-additive-models-gams" class="level2">
<h2 class="anchored" data-anchor-id="pros-and-cons-of-generalized-additive-models-gams">Pros and cons of generalized additive models (GAMs)</h2>
<div class="callout callout-style-simple callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Pros
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>GAMs can automatically model <span class="orange">non-linear</span> relationships. This can potentially make more accurate predictions for the response.</p></li>
<li><p>GAMs, as linear models, are <span class="blue">interpretable</span>: the variation of the fitted response, holding all but one predictor fixed, <span class="orange">does not depend</span> on the values of the <span class="orange">other predictors</span>.</p></li>
<li><p>In practice, this means that we can <span class="orange">plot</span> the <span class="orange">fitted functions</span> <span class="math inline">\hat{f}_j</span> separately to examine the roles of the predictors in modelling the response.</p></li>
<li><p>Additive assumption is quite strong, but it is still possible to <span class="blue">manually add interactions</span> as in the linear regression case.</p></li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Cons
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Especially when <span class="math inline">p</span> is large, it is not feasible to manually model <span class="orange">interactions</span> among covariates. GAMs do not take second-order effects (or higher) into account.</li>
</ul>
</div>
</div>
</section>
</section>
<section id="mars" class="level1">
<h1>MARS</h1>
<section id="mars-1" class="level2">
<h2 class="anchored" data-anchor-id="mars-1">MARS</h2>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Call: earth(formula=Score1~Zone+Year+Latitude+Longitude+Depth,
            data=trawl_train, pmethod="exhaustive", degree=1, penalty=3, nk=15)

Score1 =
  1.381988
  - 4.275478 * pmax(0, Longitude -    143.28) 
  + 3.983579 * pmax(0, Longitude -    143.58) 

Selected 3 of 11 terms, and 1 of 5 predictors (pmethod="exhaustive")
Termination condition: Reached nk 15
Importance: Longitude, ZoneClosed-unused, Year1993-unused, Latitude-unused, ...
Number of terms at each degree of interaction: 1 2 (additive model)
GCV 0.288727    RSS 30.98113    GRSq 0.526612    RSq 0.5658797</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>x[119,5] with colnames ZoneClosed Year1993 Latitude Longitude Depth
y[119,1] with colname Score1, and values 1.31, 1.262, 0.2022, -0.301, ...
Forward pass term 1, 2, 4, 6, 8, 10, 12, 14
Reached nk 15
After forward pass GRSq 0.474 RSq 0.673
Exhaustive pruning: number of subsets 2047   bx sing val ratio 0.0058
Prune exhaustive penalty 3 nprune null: selected 5 of 11 terms, and 3 of 5 preds
After pruning pass GRSq 0.537 RSq 0.612</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Call: earth(formula=Score1~Zone+Year+Latitude+Longitude+Depth,
            data=trawl_train, pmethod="exhaustive", trace=TRUE, degree=2,
            penalty=3, nk=15)

Score1 =
  1.317683
  -  5.388484 * pmax(0, Longitude -    143.28) 
  +  4.171636 * pmax(0, Longitude -    143.58) 
  + 0.6793061 * Year1993                       * pmax(0, Longitude -    143.05) 
  +  1.488869 * pmax(0,  Latitude -    -11.72) * pmax(0, Longitude -    143.05) 

Selected 5 of 11 terms, and 3 of 5 predictors (pmethod="exhaustive")
Termination condition: Reached nk 15
Importance: Longitude, Year1993, Latitude, ZoneClosed-unused, Depth-unused
Number of terms at each degree of interaction: 1 2 2
GCV 0.2822465    RSS 27.6649    GRSq 0.5372373    RSq 0.6123481</code></pre>
</div>
</div>
</section>
<section id="partial-plots" class="level2">
<h2 class="anchored" data-anchor-id="partial-plots">Partial plots</h2>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" href="">Linear model</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false" href="">GAM model</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" role="tab" aria-controls="tabset-1-3" aria-selected="false" href="">MARS (degree 1)</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-4" role="tab" aria-controls="tabset-1-4" aria-selected="false" href="">MARS (degree 2)</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_F_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid figure-img" width="1800"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_F_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid figure-img" width="1800"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-1-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-3-tab">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_F_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" width="1800"></p>
</figure>
</div>
</div>
</div>
</div>
<div id="tabset-1-4" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-4-tab">
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="un_F_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" width="1800"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<!-- ## The `Hitters` dataset -->
<!-- ```{r} -->
<!-- library(pdp) -->
<!-- gam_partial <- partial(m_gam_selected, pred.var = c("Years", "CHits"), grid.resolution = 40) -->
<!-- autoplot(gam_partial) + theme_light() -->
<!-- ``` -->
</section>
<section id="final-results" class="level2">
<h2 class="anchored" data-anchor-id="final-results">Final results</h2>
<div class="cell">
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<colgroup>
<col style="width: 7%">
<col style="width: 16%">
<col style="width: 19%">
<col style="width: 8%">
<col style="width: 23%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">Null model</th>
<th style="text-align: right;">Linear model</th>
<th style="text-align: right;">GAM</th>
<th style="text-align: right;">MARS (degree 1)</th>
<th style="text-align: right;">MARS (degree 2)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">MAE</td>
<td style="text-align: right;">0.611</td>
<td style="text-align: right;">0.361</td>
<td style="text-align: right;">0.315</td>
<td style="text-align: right;">0.305</td>
<td style="text-align: right;">0.334</td>
</tr>
<tr class="even">
<td style="text-align: left;">RMSE</td>
<td style="text-align: right;">0.718</td>
<td style="text-align: right;">0.463</td>
<td style="text-align: right;">0.408</td>
<td style="text-align: right;">0.390</td>
<td style="text-align: right;">0.407</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="pros-and-cons-of-mars" class="level2">
<h2 class="anchored" data-anchor-id="pros-and-cons-of-mars">Pros and cons of MARS</h2>
<div class="callout callout-style-simple callout-tip no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Pros
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>asd</li>
</ul>
</div>
</div>
<div class="callout callout-style-simple callout-warning no-icon callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Cons
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>asd</li>
</ul>
</div>
</div>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li></li>
</ul>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



<script src="un_F_files/libs/quarto-html/zenscroll-min.js"></script>
</body></html>