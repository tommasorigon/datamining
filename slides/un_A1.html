<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tommaso Rigon">

<title>A-B-C</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="un_A1_files/libs/clipboard/clipboard.min.js"></script>
<script src="un_A1_files/libs/quarto-html/quarto.js"></script>
<script src="un_A1_files/libs/quarto-html/popper.min.js"></script>
<script src="un_A1_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="un_A1_files/libs/quarto-html/anchor.min.js"></script>
<link href="un_A1_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="un_A1_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="un_A1_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="un_A1_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="un_A1_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<style>html{ scroll-behavior: smooth; }</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#about-this-unit" id="toc-about-this-unit" class="nav-link active" data-scroll-target="#about-this-unit">About this unit</a></li>
  <li><a href="#old-friends-linear-models" id="toc-old-friends-linear-models" class="nav-link" data-scroll-target="#old-friends-linear-models">Old friends: linear models</a>
  <ul class="collapse">
  <li><a href="#car-data" id="toc-car-data" class="nav-link" data-scroll-target="#car-data">Car data</a></li>
  <li><a href="#car-data-diesel-or-gas" id="toc-car-data-diesel-or-gas" class="nav-link" data-scroll-target="#car-data-diesel-or-gas">Car data (<span class="blue">diesel</span> or <span class="orange">gas</span>)</a></li>
  <li><a href="#linear-regression" id="toc-linear-regression" class="nav-link" data-scroll-target="#linear-regression">Linear regression</a></li>
  <li><a href="#scatterplot-of-the-data" id="toc-scatterplot-of-the-data" class="nav-link" data-scroll-target="#scatterplot-of-the-data">Scatterplot of the data</a></li>
  <li><a href="#regression-models" id="toc-regression-models" class="nav-link" data-scroll-target="#regression-models">Regression models</a></li>
  <li><a href="#linear-models" id="toc-linear-models" class="nav-link" data-scroll-target="#linear-models">Linear models</a></li>
  <li><a href="#matrix-notation" id="toc-matrix-notation" class="nav-link" data-scroll-target="#matrix-notation">Matrix notation</a></li>
  <li><a href="#linear-regression-estimation-i" id="toc-linear-regression-estimation-i" class="nav-link" data-scroll-target="#linear-regression-estimation-i">Linear regression: estimation I</a></li>
  <li><a href="#linear-regression-estimation-ii" id="toc-linear-regression-estimation-ii" class="nav-link" data-scroll-target="#linear-regression-estimation-ii">Linear regression: estimation II</a></li>
  <li><a href="#linear-regression-inference" id="toc-linear-regression-inference" class="nav-link" data-scroll-target="#linear-regression-inference">Linear regression: inference</a></li>
  <li><a href="#car-data-a-preliminary-model" id="toc-car-data-a-preliminary-model" class="nav-link" data-scroll-target="#car-data-a-preliminary-model">Car data, a preliminary model</a></li>
  <li><a href="#a-first-model-estimated-coefficients" id="toc-a-first-model-estimated-coefficients" class="nav-link" data-scroll-target="#a-first-model-estimated-coefficients">A first model: estimated coefficients</a></li>
  <li><a href="#a-first-model-fitted-values" id="toc-a-first-model-fitted-values" class="nav-link" data-scroll-target="#a-first-model-fitted-values">A first model: fitted values</a></li>
  <li><a href="#a-first-model-graphical-diagnostics" id="toc-a-first-model-graphical-diagnostics" class="nav-link" data-scroll-target="#a-first-model-graphical-diagnostics">A first model: graphical diagnostics</a></li>
  <li><a href="#comments-and-criticisms" id="toc-comments-and-criticisms" class="nav-link" data-scroll-target="#comments-and-criticisms">Comments and criticisms</a></li>
  <li><a href="#variable-transformation" id="toc-variable-transformation" class="nav-link" data-scroll-target="#variable-transformation">Variable transformation</a></li>
  <li><a href="#second-model-fitted-values" id="toc-second-model-fitted-values" class="nav-link" data-scroll-target="#second-model-fitted-values">Second model: fitted values</a></li>
  <li><a href="#second-model-graphical-diagnostics" id="toc-second-model-graphical-diagnostics" class="nav-link" data-scroll-target="#second-model-graphical-diagnostics">Second model: graphical diagnostics</a></li>
  <li><a href="#comments-and-criticisms-1" id="toc-comments-and-criticisms-1" class="nav-link" data-scroll-target="#comments-and-criticisms-1">Comments and criticisms</a></li>
  <li><a href="#a-third-model-additional-variables" id="toc-a-third-model-additional-variables" class="nav-link" data-scroll-target="#a-third-model-additional-variables">A third model: additional variables</a></li>
  <li><a href="#a-third-model-graphical-diagnostics" id="toc-a-third-model-graphical-diagnostics" class="nav-link" data-scroll-target="#a-third-model-graphical-diagnostics">A third model: graphical diagnostics</a></li>
  <li><a href="#comments-and-criticisms-2" id="toc-comments-and-criticisms-2" class="nav-link" data-scroll-target="#comments-and-criticisms-2">Comments and criticisms</a></li>
  </ul></li>
  <li><a href="#computational-aspects" id="toc-computational-aspects" class="nav-link" data-scroll-target="#computational-aspects">Computational aspects</a>
  <ul class="collapse">
  <li><a href="#how-to-obtain-the-least-squares-estimate" id="toc-how-to-obtain-the-least-squares-estimate" class="nav-link" data-scroll-target="#how-to-obtain-the-least-squares-estimate">How to obtain the least squares estimate?</a></li>
  <li><a href="#the-normal-equations" id="toc-the-normal-equations" class="nav-link" data-scroll-target="#the-normal-equations">The normal equations</a></li>
  <li><a href="#cholesky-factorization" id="toc-cholesky-factorization" class="nav-link" data-scroll-target="#cholesky-factorization">Cholesky factorization</a></li>
  <li><a href="#cholesky-factorization-and-least-squares" id="toc-cholesky-factorization-and-least-squares" class="nav-link" data-scroll-target="#cholesky-factorization-and-least-squares">Cholesky factorization and least squares</a></li>
  <li><a href="#forward-and-backward-substitutions" id="toc-forward-and-backward-substitutions" class="nav-link" data-scroll-target="#forward-and-backward-substitutions">Forward and backward substitutions</a></li>
  <li><a href="#computational-complexity" id="toc-computational-complexity" class="nav-link" data-scroll-target="#computational-complexity">Computational complexity</a></li>
  <li><a href="#error-propagation-in-normal-equations" id="toc-error-propagation-in-normal-equations" class="nav-link" data-scroll-target="#error-propagation-in-normal-equations">Error propagation in normal equations</a></li>
  <li><a href="#condition-numbers-and-normal-equations" id="toc-condition-numbers-and-normal-equations" class="nav-link" data-scroll-target="#condition-numbers-and-normal-equations">Condition numbers and normal equations</a></li>
  <li><a href="#the-qr-decomposition" id="toc-the-qr-decomposition" class="nav-link" data-scroll-target="#the-qr-decomposition">The QR decomposition</a></li>
  </ul></li>
  <li><a href="#iterative-methods" id="toc-iterative-methods" class="nav-link" data-scroll-target="#iterative-methods">Iterative methods</a></li>
  <li><a href="#generalized-linear-models" id="toc-generalized-linear-models" class="nav-link" data-scroll-target="#generalized-linear-models">Generalized linear models</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">A-B-C</h1>
<p class="subtitle lead">Data Mining - CdL CLAMSES</p>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <span class="orange">Tommaso Rigon</span> 
  </div>
    <div class="quarto-title-meta-contents">
        <p class="affiliation">
            <em>Università degli Studi di Milano-Bicocca</em>
          </p>
      </div>
    </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  

</header>

<section id="about-this-unit" class="level2">
<h2 class="anchored" data-anchor-id="about-this-unit">About this unit</h2>
<div class="columns">
<div class="column" style="width:40%;">
<p><img src="img/ABC.png" class="img-fluid"> <em>“Everything should be made as simple as possible, but not simpler”</em> Attributed to Albert Einstein</p>
</div><div class="column" style="width:60%;">
<ul>
<li><p>In this unit we will cover three important <span class="orange">topics</span>:</p>
<ul>
<li>Linear models and modelling process</li>
<li>Computational aspects</li>
<li>Generalized linear models (GLMs)</li>
</ul></li>
<li><p>The <span class="blue">computational aspects</span> of linear models will be novel to most of you…</p></li>
<li><p>… but you should be already <span class="orange">very familiar</span> with linear models and GLMs!</p></li>
<li><p>If do not remember much about them, use this first week of lectures to catch up (or study) from the material of previous courses.</p></li>
</ul>
<!-- -   A [short introduction]{.blue} to the topic is also offered in -->
<!--     Azzalini & Scarpa (2011), Chapter 2 and Appendix A.3. -->
</div>
</div>
</section>
<section id="old-friends-linear-models" class="level1">
<h1>Old friends: linear models</h1>
<section id="car-data" class="level2">
<h2 class="anchored" data-anchor-id="car-data">Car data</h2>
<ul>
<li>We consider data for <span class="math inline">n = 203</span> models of cars in circulation in 1985 in the USA.</li>
<li>We want to identify a relationship that allows to <span class="blue">predict</span> the distance covered per unit of fuel, as a function of the vehicle characteristics.</li>
<li>We consider the following <span class="orange">continuous variables</span>:
<ul>
<li>The city distance per unit of fuel (km/L, <code>city.distance</code>)</li>
<li>The engine size (L, <code>engine.size</code>)</li>
<li>The number of cylinders (<code>n.cylinders</code>)</li>
<li>The curb weight (kg, <code>curb.weight</code>)</li>
</ul></li>
<li>We also considered the <span class="orange">categorical variable</span> fuel type (gasoline or diesel, <code>fuel</code>).</li>
</ul>
</section>
<section id="car-data-diesel-or-gas" class="level2">
<h2 class="anchored" data-anchor-id="car-data-diesel-or-gas">Car data (<span class="blue">diesel</span> or <span class="orange">gas</span>)</h2>
<div class="cell" data-hash="un_A1_cache/html/unnamed-chunk-1_4a807b89412377f2f99f8165a42109c9">
<div class="cell-output-display">
<p><img src="un_A1_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="2100"></p>
</div>
</div>
</section>
<section id="linear-regression" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression">Linear regression</h2>
<ul>
<li><p>At the moment, let us focus on <code>city.distance</code> (<span class="math inline">y</span>), <code>engine.size</code> (<span class="math inline">x</span>) and <code>fuel</code> (<span class="math inline">z</span>).</p></li>
<li><p>The simplest model we can come up with is a <span class="orange">linear regression</span> line: <span class="math display">
y = \beta_0 + \beta_1 x + \epsilon,
</span> where <span class="math inline">\epsilon</span> is a non-observable “error” term, having zero mean and variance <span class="math inline">\sigma^2</span>.</p></li>
</ul>
<div class="incremental">
<ul>
<li><p>We are looking for an estimate for the <span class="blue">unknown regression parameters</span> <span class="math inline">\beta_0</span> and <span class="math inline">\beta_1</span>.</p></li>
<li><p>Such an estimate could be obtained by ordinary least squares (OLS)…</p></li>
</ul>
</div>
<div class="incremental">
<ul>
<li><p>… but the next plot clearly suggests that the relationship between <code>city.distance</code> and <code>engine.size</code> is <span class="orange">not</span> well approximated by a <span class="orange">linear</span> function.</p></li>
<li><p>… and also that <code>fuel</code> has an non-negligible effect on the response.</p></li>
</ul>
</div>
</section>
<section id="scatterplot-of-the-data" class="level2">
<h2 class="anchored" data-anchor-id="scatterplot-of-the-data">Scatterplot of the data</h2>
<div class="cell" data-hash="un_A1_cache/html/unnamed-chunk-2_1bf1850f2117e5b58756b66e7d12f7b4">
<div class="cell-output-display">
<p><img src="un_A1_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="2100"></p>
</div>
</div>
</section>
<section id="regression-models" class="level2">
<h2 class="anchored" data-anchor-id="regression-models">Regression models</h2>
<ul>
<li>A more <span class="orange">general formulation</span> for modeling the relationship between a vector of covariates <span class="math inline">\bm{x} = (x_1,\dots,x_p)^T \in \mathbb{R}^p</span> and a response <span class="math inline">y \in \mathbb{R}</span> is <span class="math display">
y = f(\bm{x}; \beta) + \epsilon.
</span></li>
</ul>
<div class="incremental">
<ul>
<li>To estimate the unknown parameters <span class="math inline">\beta</span>, a possibility is to rely on <span class="blue">least squares criterion</span>: we seek the <span class="orange">minimum</span> of the objective function <span class="math display">
D(\beta) = \sum_{i=1}^n\{y_i - f(\bm{x}_i; \beta)\}^2,
</span> using <span class="math inline">n</span> pairs of observations <span class="math inline">(\bm{x}_i, y_i)</span>, for <span class="math inline">i = 1,\dots,n</span>.</li>
<li>The solution to this minimization problem is denoted by <span class="math inline">\hat{\beta}</span>.</li>
</ul>
</div>
<div class="incremental">
<ul>
<li>The <span class="blue">predicted values</span> <span class="math inline">\hat{y}_i</span> are then obtained as <span class="math inline">\hat{y}_i = f(\bm{x}_i; \hat{\beta})</span>, for <span class="math inline">i=1,\dots,n.</span></li>
</ul>
</div>
</section>
<section id="linear-models" class="level2">
<h2 class="anchored" data-anchor-id="linear-models">Linear models</h2>
<ul>
<li><p>There are several directions to model <code>city.distance</code> (<span class="math inline">y</span>), <code>engine.size</code> (<span class="math inline">x</span>) and <code>fuel</code> (<span class="math inline">z</span>) in a more flexible way.</p></li>
<li><p>For instance, we could consider a <span class="orange">polynomial term</span> combined with a <span class="blue">dummy variable</span> <span class="math display">
f(\bm{x}; \beta) = \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3 + \beta_4 I(z = \texttt{gas}).
</span></p></li>
<li><p><span class="orange">Remark</span>. This model is <span class="blue">linear in the parameters</span>, but it can capture non-linear patterns!</p></li>
</ul>
<div class="incremental">
<div class="callout-note callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li>The above specification is a special instance of <span class="blue">linear model</span>, in which <span class="math display">
f(\bm{x}; \beta) = \beta_0  + \beta_1 x_1 + \cdots + \beta_p x_{p-1} = \bm{x}_i^T\beta,
</span> where <span class="math inline">\bm{x} = (1, x_1, \dots,x_{p-1})^T</span> is a <span class="math inline">p</span>-dimensional vector of <span class="orange">covariates</span> and <span class="math inline">\beta = (\beta_0,\dots,\beta_{p-1})^T</span> is the corresponding vector of <span class="orange">coefficients</span>.</li>
</ul>
</div>
</div>
</div>
</div>
</section>
<section id="matrix-notation" class="level2">
<h2 class="anchored" data-anchor-id="matrix-notation">Matrix notation</h2>
<ul>
<li><p>It is often convenient to express the quantities of linear models in <span class="orange">matrix notation</span>.</p></li>
<li><p>The <span class="blue">response values</span> are <span class="math inline">\bm{y} = (y_1,\dots,y_n)^T</span>.</p></li>
<li><p>The <span class="blue">design matrix</span> is a <span class="math inline">n \times p</span> matrix, comprising the covariate’s values, defined by <span class="math display">
\bm{X} = (\bm{x}_1, \dots,\bm{x}_n)^T =
\begin{bmatrix}
1 &amp; x_{1,1} &amp; \cdots &amp; x_{1,p-1}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_{n, 1} &amp; \cdots &amp; x_{n, p-1}
\end{bmatrix}.
</span></p></li>
<li><p>Thus, the linear model can be written using the compact notation: <span class="math display">
\bm{y} = \bm{X}\beta + \bm{\epsilon},
</span> where <span class="math inline">\bm{\epsilon} = (\epsilon_1,\dots,\epsilon_n)^T</span> is a vector of iid error terms with zero mean and variance <span class="math inline">\sigma^2</span>.</p></li>
</ul>
</section>
<section id="linear-regression-estimation-i" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression-estimation-i">Linear regression: estimation I</h2>
<ul>
<li><p>The optimal set of coefficients <span class="math inline">\hat{\beta}</span> is the minimizer of the least squared criterion <span class="math display">
D(\beta) = (\bm{y} - \bm{X}\beta)^T(\bm{y} - \bm{X}\beta) = ||\bm{y} - \bm{X}\beta||^2,
</span> where <span class="math inline">||\bm{y}|| = \sqrt{y_1^2 + \cdots + y_n^2}</span> is the <span class="blue">Euclidean norm</span>.</p></li>
<li><p>The quantity <span class="math inline">D(\beta)</span> is also known as <span class="orange">residual sum of squares (RSS)</span>.</p></li>
</ul>
<div class="incremental">
<div class="callout-note callout callout-style-simple no-icon">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-body-container">
<ul>
<li>If the design matrix has <span class="blue">full rank</span>, that is if <span class="math inline">\text{rk}(\bm{X}^T\bm{X}) = p</span>, then the <span class="orange">least square estimate</span> has an explicit solution: <span class="math display">
\hat{\beta} = (\bm{X}^T\bm{X})^{-1}\bm{X}^T \bm{y}.
</span></li>
</ul>
</div>
</div>
</div>
</div>
</section>
<section id="linear-regression-estimation-ii" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression-estimation-ii">Linear regression: estimation II</h2>
<ul>
<li><p>Consequently, the predicted values are <span class="math display">
\hat{\bm{y}} = \bm{X}\hat{\beta} = \bm{P}\bm{y}, \qquad \bm{P} = \bm{X}(\bm{X}^T\bm{X})^{-1}\bm{X}^T.
</span></p></li>
<li><p><span class="math inline">\bm{P}</span> is a <span class="math inline">n \times n</span> <span class="orange">projection matrix</span> matrix sometimes called <span class="blue">hat matrix</span>. It can be shown that <span class="math inline">\text{tr}(\bm{P}) = \text{rk}(\bm{P}) = p</span>. Moreover, it holds <span class="math inline">\bm{P} = \bm{P}^T</span> and <span class="math inline">\bm{P}^2 = \bm{P}</span>.</p></li>
<li><p>The quantity <span class="math inline">D(\hat{\beta})</span> is the <span class="blue">deviance</span>, which is equal to <span class="math display">
D(\hat{\beta}) = ||\bm{y} - \hat{\bm{y}}||^2 = \bm{y}^T(I_n - \bm{P})\bm{y}.
</span></p></li>
<li><p>A typical estimate for the <span class="orange">residual variance</span> <span class="math inline">\sigma^2</span> is then given by <span class="math display">
s^2 = \frac{D(\hat{\beta})}{n - p} = \frac{1}{n-p}\sum_{i=1}^n(y_i - \bm{x}_i^T\hat{\beta})^2.
</span></p></li>
</ul>
</section>
<section id="linear-regression-inference" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression-inference">Linear regression: inference</h2>
<ul>
<li><p>Let us additionally assume that the errors follow a Gaussian distribution: <span class="math inline">\epsilon_i \overset{\text{iid}}{\sim} N(0, \sigma^2)</span>.</p></li>
<li><p>This implies that the distribution of the estimator <span class="math inline">\hat{\beta}</span> is <span class="math display">
\hat{\beta} \sim N_p(\beta, \sigma^2 (X^TX)^{-1}).
</span></p></li>
<li><p>Hence, the estimator <span class="math inline">\hat{\beta}</span> is <span class="orange">unbiased</span> and its <span class="blue">variance</span> can be estimated by <span class="math display">
\widehat{\text{var}}(\hat{\beta}) = s^2 (X^TX)^{-1}.
</span></p></li>
<li><p>The <span class="orange">standard errors</span> of the components of beta correspond to the square root of the diagonal of the above covariance matrix.</p></li>
<li><p>Confidence interval and Wald’s tests can be obtained through classical inferential theory.</p></li>
</ul>
</section>
<section id="car-data-a-preliminary-model" class="level2">
<h2 class="anchored" data-anchor-id="car-data-a-preliminary-model">Car data, a preliminary model</h2>
<ul>
<li><p>A first model to predict <code>city.distance</code> (<span class="math inline">y</span>) via <code>engine.size</code> (<span class="math inline">x</span>) and <code>fuel</code> (<span class="math inline">z</span>) is <span class="math display">
  f(\bm{x}; \beta) = \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3 + \beta_4 I(z = \texttt{gas}).
  </span></p></li>
<li><p>By looking at the plot of the data, it is plausible that we need a <span class="orange">polynomial</span> of degree <span class="math inline">3</span> or <span class="math inline">4</span></p></li>
<li><p>It is also clear from the plot that <code>fuel</code> is a relevant variable. Categorical variable should be <span class="orange">encoded</span> using <span class="blue">indicator variables</span>.</p></li>
</ul>
<div class="incremental">
<ul>
<li>To evaluate the goodness of fit, we can calculate the <span class="orange">coefficient of determination</span>:</li>
</ul>
<p><span class="math display">
R^2 = 1 - \frac{\text{(``Residual deviance'')}}{\text{(``Total deviance'')}} = 1 - \frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{\sum_{i=1}^n(y_i - \bar{y})^2}.
</span></p>
</div>
</section>
<section id="a-first-model-estimated-coefficients" class="level2">
<h2 class="anchored" data-anchor-id="a-first-model-estimated-coefficients">A first model: estimated coefficients</h2>
<ul>
<li>We obtain the following <span class="orange">summary</span> for the regression coefficients <span class="math inline">\hat{\beta}</span>.</li>
</ul>
<div class="cell" data-hash="un_A1_cache/html/unnamed-chunk-3_18e8902f2a9f42d1112645174b2fb35c">
<div class="cell-output-display">
<table class="table table-sm table-striped">
<colgroup>
<col style="width: 23%">
<col style="width: 12%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 10%">
<col style="width: 12%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
<th style="text-align: right;">conf.low</th>
<th style="text-align: right;">conf.high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">28.045</td>
<td style="text-align: right;">3.076</td>
<td style="text-align: right;">9.119</td>
<td style="text-align: right;">0.000</td>
<td style="text-align: right;">21.980</td>
<td style="text-align: right;">34.110</td>
</tr>
<tr class="even">
<td style="text-align: left;">engine.size</td>
<td style="text-align: right;">-10.980</td>
<td style="text-align: right;">3.531</td>
<td style="text-align: right;">-3.109</td>
<td style="text-align: right;">0.002</td>
<td style="text-align: right;">-17.943</td>
<td style="text-align: right;">-4.016</td>
</tr>
<tr class="odd">
<td style="text-align: left;">I(engine.size^2)</td>
<td style="text-align: right;">2.098</td>
<td style="text-align: right;">1.271</td>
<td style="text-align: right;">1.651</td>
<td style="text-align: right;">0.100</td>
<td style="text-align: right;">-0.409</td>
<td style="text-align: right;">4.604</td>
</tr>
<tr class="even">
<td style="text-align: left;">I(engine.size^3)</td>
<td style="text-align: right;">-0.131</td>
<td style="text-align: right;">0.139</td>
<td style="text-align: right;">-0.939</td>
<td style="text-align: right;">0.349</td>
<td style="text-align: right;">-0.406</td>
<td style="text-align: right;">0.144</td>
</tr>
<tr class="odd">
<td style="text-align: left;">fuelgas</td>
<td style="text-align: right;">-3.214</td>
<td style="text-align: right;">0.427</td>
<td style="text-align: right;">-7.523</td>
<td style="text-align: right;">0.000</td>
<td style="text-align: right;">-4.057</td>
<td style="text-align: right;">-2.372</td>
</tr>
</tbody>
</table>
</div>
</div>
<ul>
<li>The coefficient <span class="math inline">R^2</span> and <span class="math inline">s</span> are estimated as follows:</li>
</ul>
<div class="cell" data-hash="un_A1_cache/html/unnamed-chunk-4_5a1cf4598db95b8d5b60005f7fc37629">
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: right;">r.squared</th>
<th style="text-align: right;">sigma</th>
<th style="text-align: right;">deviance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.5973454</td>
<td style="text-align: right;">1.790362</td>
<td style="text-align: right;">634.6687</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="a-first-model-fitted-values" class="level2">
<h2 class="anchored" data-anchor-id="a-first-model-fitted-values">A first model: fitted values</h2>
<div class="cell" data-hash="un_A1_cache/html/unnamed-chunk-5_f42d691a14e7f7b65d3767856c6150b9">
<div class="cell-output-display">
<p><img src="un_A1_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="2100"></p>
</div>
</div>
</section>
<section id="a-first-model-graphical-diagnostics" class="level2">
<h2 class="anchored" data-anchor-id="a-first-model-graphical-diagnostics">A first model: graphical diagnostics</h2>
<div class="cell" data-hash="un_A1_cache/html/unnamed-chunk-6_e2d1eb25dfdb29717c476775516cd851">
<div class="cell-output-display">
<p><img src="un_A1_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="2100"></p>
</div>
</div>
</section>
<section id="comments-and-criticisms" class="level2">
<h2 class="anchored" data-anchor-id="comments-and-criticisms">Comments and criticisms</h2>
<ul>
<li>The overall fit <span class="blue">seems satisfactory</span> at first glance, especially if we aim at predicting the urban distance of cars when average engine size (i.e., between <span class="math inline">1.5L</span> and <span class="math inline">3L</span>).</li>
</ul>
<div class="incremental">
<ul>
<li>However, the plot of the <span class="orange">residuals</span> <span class="math inline">r_i = y_i - \hat{y}_i</span> suggests that there the homoschedasticity assumption, i.e.&nbsp;<span class="math inline">\mathbb{E}(\epsilon_i) = \sigma^2</span>, might be violated.</li>
</ul>
</div>
<div class="incremental">
<ul>
<li><p>Also, this model in not suitable for <span class="orange">extrapolation</span>. Indeed:</p></li>
<li><p>It has no grounding in physics or engineering, which leads to difficulties in the interpretation of the trend and/or paradoxical situations.</p></li>
<li><p>For example, the curve of the set of gasoline cars shows a local minimum around <span class="math inline">4.6 L</span> and then rises again!</p></li>
</ul>
</div>
</section>
<section id="variable-transformation" class="level2">
<h2 class="anchored" data-anchor-id="variable-transformation">Variable transformation</h2>
<ul>
<li><p>A major advantage of linear models is that they can exploit non-linear relationship via <span class="blue">variable transformations</span>.</p></li>
<li><p>This gives the statistician an lot of modelling flexibility, for instance:</p></li>
</ul>
<p><span class="math display">
\log{y} = \beta_0 + \beta_1 \log{x} + \beta_2 I(z = \texttt{gas}).
</span></p>
<div class="incremental">
<ul>
<li>This specification is <span class="orange">linear in the parameters</span>, it fixes the domain issues, and imposes a monotone relationship between engine size and consumption.</li>
</ul>
<div class="cell" data-hash="un_A1_cache/html/unnamed-chunk-7_2bc96f54f9dfed66f89e5706343afe86">
<div class="cell-output-display">
<table class="table table-sm table-striped">
<colgroup>
<col style="width: 26%">
<col style="width: 11%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 10%">
<col style="width: 11%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
<th style="text-align: right;">conf.low</th>
<th style="text-align: right;">conf.high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">3.060</td>
<td style="text-align: right;">0.047</td>
<td style="text-align: right;">64.865</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">2.967</td>
<td style="text-align: right;">3.153</td>
</tr>
<tr class="even">
<td style="text-align: left;">I(log(engine.size))</td>
<td style="text-align: right;">-0.682</td>
<td style="text-align: right;">0.040</td>
<td style="text-align: right;">-17.129</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">-0.760</td>
<td style="text-align: right;">-0.603</td>
</tr>
<tr class="odd">
<td style="text-align: left;">fuelgas</td>
<td style="text-align: right;">-0.278</td>
<td style="text-align: right;">0.038</td>
<td style="text-align: right;">-7.344</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">-0.353</td>
<td style="text-align: right;">-0.203</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="second-model-fitted-values" class="level2">
<h2 class="anchored" data-anchor-id="second-model-fitted-values">Second model: fitted values</h2>
<div class="cell" data-hash="un_A1_cache/html/unnamed-chunk-8_94b46df153cf1fa63472d798b29c840e">
<div class="cell-output-display">
<p><img src="un_A1_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid" width="2100"></p>
</div>
</div>
</section>
<section id="second-model-graphical-diagnostics" class="level2">
<h2 class="anchored" data-anchor-id="second-model-graphical-diagnostics">Second model: graphical diagnostics</h2>
<div class="cell" data-hash="un_A1_cache/html/unnamed-chunk-9_aed3090eb566ec155f578f1e4ff3518d">
<div class="cell-output-display">
<p><img src="un_A1_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" width="2100"></p>
</div>
</div>
</section>
<section id="comments-and-criticisms-1" class="level2">
<h2 class="anchored" data-anchor-id="comments-and-criticisms-1">Comments and criticisms</h2>
<ul>
<li>The <span class="blue">goodness of fit</span> indices are the following:</li>
</ul>
<div class="cell" data-hash="un_A1_cache/html/unnamed-chunk-10_7b39916e6db6c34a0de2f812eda82d8c">
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: right;">r.squared.original</th>
<th style="text-align: right;">r.squared</th>
<th style="text-align: right;">sigma</th>
<th style="text-align: right;">deviance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.5847555</td>
<td style="text-align: right;">0.6196093</td>
<td style="text-align: right;">0.1600278</td>
<td style="text-align: right;">5.121777</td>
</tr>
</tbody>
</table>
</div>
</div>
<ul>
<li><span class="blue">Apple</span> and <span class="orange">oranges</span>: the <span class="math inline">R^2</span> must be computed and compared using the same scale!</li>
</ul>
<div class="incremental">
<ul>
<li><p>This second model is <span class="blue">more parsimonious</span> and yet it reaches similar predictive performance.</p></li>
<li><p>It is also more coherent with the nature of the data: the predictions cannot be negative and the relationship between engine size and the consumption is monotone.</p></li>
<li><p>There is still some heteroschedasticity in the residuals — is this due to a missing covariate that has not been included into the model?</p></li>
</ul>
</div>
</section>
<section id="a-third-model-additional-variables" class="level2">
<h2 class="anchored" data-anchor-id="a-third-model-additional-variables">A third model: additional variables</h2>
<ul>
<li>Let us consider <span class="orange">two additional variables</span>: <code>curb.weight</code> (<span class="math inline">w</span>) and <code>n.cylinders</code> (<span class="math inline">v</span>). A modified model could be: <span class="math display">
\log{y} = \beta_0 + \beta_1 \log{x} +  \beta_2 \log{w} + \beta_3 I(z = \texttt{gas}) + \beta_4 I(v = 2).
</span></li>
</ul>
<div class="incremental">
<div class="cell" data-hash="un_A1_cache/html/unnamed-chunk-11_53680696a65b5dcde91782e4649fd3e0">
<div class="cell-output-display">
<table class="table table-sm table-striped">
<colgroup>
<col style="width: 26%">
<col style="width: 11%">
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 10%">
<col style="width: 11%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
<th style="text-align: right;">conf.low</th>
<th style="text-align: right;">conf.high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">9.423</td>
<td style="text-align: right;">0.482</td>
<td style="text-align: right;">19.549</td>
<td style="text-align: right;">0.000</td>
<td style="text-align: right;">8.472</td>
<td style="text-align: right;">10.373</td>
</tr>
<tr class="even">
<td style="text-align: left;">I(log(engine.size))</td>
<td style="text-align: right;">-0.180</td>
<td style="text-align: right;">0.051</td>
<td style="text-align: right;">-3.504</td>
<td style="text-align: right;">0.001</td>
<td style="text-align: right;">-0.281</td>
<td style="text-align: right;">-0.079</td>
</tr>
<tr class="odd">
<td style="text-align: left;">I(log(curb.weight))</td>
<td style="text-align: right;">-0.943</td>
<td style="text-align: right;">0.072</td>
<td style="text-align: right;">-13.066</td>
<td style="text-align: right;">0.000</td>
<td style="text-align: right;">-1.085</td>
<td style="text-align: right;">-0.800</td>
</tr>
<tr class="even">
<td style="text-align: left;">fuelgas</td>
<td style="text-align: right;">-0.353</td>
<td style="text-align: right;">0.022</td>
<td style="text-align: right;">-15.934</td>
<td style="text-align: right;">0.000</td>
<td style="text-align: right;">-0.396</td>
<td style="text-align: right;">-0.309</td>
</tr>
<tr class="odd">
<td style="text-align: left;">cylinders2TRUE</td>
<td style="text-align: right;">-0.481</td>
<td style="text-align: right;">0.052</td>
<td style="text-align: right;">-9.301</td>
<td style="text-align: right;">0.000</td>
<td style="text-align: right;">-0.584</td>
<td style="text-align: right;">-0.379</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="a-third-model-graphical-diagnostics" class="level2">
<h2 class="anchored" data-anchor-id="a-third-model-graphical-diagnostics">A third model: graphical diagnostics</h2>
<div class="cell" data-hash="un_A1_cache/html/unnamed-chunk-12_216428d059ae4c8e94c87954799b0cf8">
<div class="cell-output-display">
<p><img src="un_A1_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid" width="2100"></p>
</div>
</div>
</section>
<section id="comments-and-criticisms-2" class="level2">
<h2 class="anchored" data-anchor-id="comments-and-criticisms-2">Comments and criticisms</h2>
<ul>
<li>The goodness of fit greatly <span class="blue">improved</span>:</li>
</ul>
<div class="cell" data-hash="un_A1_cache/html/unnamed-chunk-13_46846dfce63c8ee44af7793e20549faf">
<div class="cell-output-display">
<table class="table table-sm table-striped">
<thead>
<tr class="header">
<th style="text-align: right;">r.squared.original</th>
<th style="text-align: right;">r.squared</th>
<th style="text-align: right;">sigma</th>
<th style="text-align: right;">deviance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.869048</td>
<td style="text-align: right;">0.8819199</td>
<td style="text-align: right;">0.0896089</td>
<td style="text-align: right;">1.589891</td>
</tr>
</tbody>
</table>
</div>
</div>
<ul>
<li><p>We took care of the <span class="orange">outliers</span>, which it turns out are identified by the group of cars having 2 cylinders.</p></li>
<li><p>The diagnostic plots are also very much improved, although still not perfect.</p></li>
</ul>
<div class="incremental">
<ul>
<li>The estimates are coherent with our expectations, based on common knowledge. Have a look at the textbook (A&amp;S) for a detailed explaination about <span class="math inline">\beta_4</span>!</li>
</ul>
</div>
</section>
</section>
<section id="computational-aspects" class="level1">
<h1>Computational aspects</h1>
<section id="how-to-obtain-the-least-squares-estimate" class="level2">
<h2 class="anchored" data-anchor-id="how-to-obtain-the-least-squares-estimate">How to obtain the least squares estimate?</h2>
<ul>
<li><p>In undergraduate courses it is often suggested that the least square estimate should be computed using the formula <span class="math display">
\hat{\beta} = (\bm{X}^T\bm{X})^{-1}\bm{X}^T \bm{y},
</span> that is, using the R code <code>solve(t(X) %*% X) %*% t(X) %*% y</code>.</p></li>
<li><p>This is <span class="orange">theoretically correct</span> and it works reasonably well in many simple cases.</p></li>
</ul>
<div class="incremental">
<ul>
<li><p>However, in real life, when we have a lot of data (large <span class="math inline">n</span>) and correlated variables, the above code is <span class="orange">computationally inefficient</span> and <span class="blue">numerically inaccurate</span>.</p></li>
<li><p>The main computational bottleneck is about obtaining the inverse of <span class="math inline">\bm{X}^T\bm{X}</span>, which is very costly and often numerically unstable, especially when the predictors are almost collinear.</p></li>
</ul>
</div>
</section>
<section id="the-normal-equations" class="level2">
<h2 class="anchored" data-anchor-id="the-normal-equations">The normal equations</h2>
<ul>
<li><p>Consider the following system of equations (<span class="orange">normal equations</span>):<span class="math display">
\bm{X}^T\bm{X} \beta = \bm{X}^T \bm{y}.
</span></p></li>
<li><p>This system could be solved using <code>solve(crossprod(X), crossprod(X, y))</code>.</p></li>
<li><p>The above R command avoids the computation of <span class="math inline">(\bm{X}^T\bm{X})^{-1}</span> and it is preferable compared to the “direct solution”. However, it does not exploit the properties of the matrix <span class="math inline">\bm{X}^T\bm{X}</span>.</p></li>
</ul>
<div class="incremental">
<div class="callout-note callout callout-style-simple no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Proposition A.1
</div>
</div>
<div class="callout-body-container callout-body">
<p>Suppose <span class="math inline">\bm{X} \in \mathbb{R}^{n \times p}</span> with <span class="math inline">n \ge p</span> has full rank, that is <span class="math inline">\text{rk}(\bm{X}) = p</span>. Then, the matrix <span class="math display">
\bm{X}^T\bm{X}
</span> is <span class="blue">symmetric</span> and <span class="orange">positive definite</span>.</p>
</div>
</div>
</div>
</section>
<section id="cholesky-factorization" class="level2">
<h2 class="anchored" data-anchor-id="cholesky-factorization">Cholesky factorization</h2>
<ul>
<li>Recall (from your favorite linear algebra textbook) that a <span class="blue">symmetric</span> matrix <span class="math inline">\bm{A} \in \mathbb{R}^{p \times p}</span> is <span class="orange">positive definite</span> if and only if one the following properties is satisfied
<ul>
<li>The quadratic form <span class="math inline">\bm{x}^T \bm{A} \bm{x} &gt; 0</span> for all <span class="math inline">\bm{x} \in \mathbb{R}^p \neq 0</span>.</li>
<li>The eigenvalues <span class="math inline">\lambda_1,\dots,\lambda_p</span> of <span class="math inline">\bm{A}</span> are all strictly positive.</li>
</ul></li>
</ul>
<div class="callout-note callout callout-style-simple no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Theorem (Cholesky factorization)
</div>
</div>
<div class="callout-body-container callout-body">
<p>Let <span class="math inline">\bm{A} \in \mathbb{R}^{p \times p}</span> be a symmetric and positive definite matrix. Then, there exists a unique <span class="orange">upper triangular</span> <span class="math inline">p \times p</span> matrix <span class="math inline">\bm{R}</span> with positive entries such that <span class="math display">
\bm{A} = \bm{R}^T\bm{R}.
</span></p>
</div>
</div>
</section>
<section id="cholesky-factorization-and-least-squares" class="level2">
<h2 class="anchored" data-anchor-id="cholesky-factorization-and-least-squares">Cholesky factorization and least squares</h2>
<ul>
<li><p>Let <span class="math inline">\bm{R}^T\bm{R}</span> be the Cholesky factorization of the matrix <span class="math inline">\bm{X}^T\bm{X}</span>. Then, the <span class="orange">normal equations</span> can be written as <span class="math display">
\bm{R}^T\bm{R} \beta = \bm{X}^T \bm{y},
</span> which can be can be solved in two steps.</p></li>
<li><p><span class="blue">Step 1 (Forwardsolve)</span>. Solve with respect to <span class="math inline">z</span> the system of equations <span class="math display">
\bm{R}^T z = \bm{X}^T \bm{y}.
</span></p></li>
<li><p><span class="blue">Step 2 (Backsolve)</span>. Given <span class="math inline">z</span>, now solve with respect to <span class="math inline">\beta</span> the system of equations <span class="math display">
\bm{R} \beta = z.
</span></p></li>
</ul>
</section>
<section id="forward-and-backward-substitutions" class="level2">
<h2 class="anchored" data-anchor-id="forward-and-backward-substitutions">Forward and backward substitutions</h2>
<ul>
<li><p>The solution of <span class="blue">triangular systems</span> is <span class="orange">straightforward</span>.</p></li>
<li><p>As an example, consider the following <span class="math inline">3 \times 3</span> lower triangular system: <span class="math display">
\begin{bmatrix}
l_{11} &amp; 0 &amp; 0 \\
l_{21} &amp; l_{22} &amp; 0 \\
l_{31} &amp; l_{32} &amp; l_{33} \\
\end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} = \begin{bmatrix}
b_1 \\ b_2 \\ b_3
\end{bmatrix}.
</span></p></li>
<li><p>The solution for <span class="math inline">x_1,x_2,x_3</span> can be found sequentially: <span class="math display">
x_1 = \frac{b_1}{l_{11}}, \qquad x_2 = \frac{b_2 -  l_{21}x_1}{l_{22}}, \qquad x_3 = \frac{b_3 - l_{31}x_1 - l_{32}x_2}{l_{33}}.
</span></p></li>
</ul>
<div class="incremental">
<ul>
<li>Finding the inverse <span class="math inline">\bm{R}^{-1}</span> is simple, again because <span class="math inline">\bm{R}</span> is upper triangular. Also note that <span class="math display">
(\bm{X}^T \bm{X})^{-1} = (\bm{R}^T \bm{R})^{-1} = \bm{R}^{-1} (\bm{R}^{-1})^T.
</span></li>
</ul>
</div>
</section>
<section id="computational-complexity" class="level2">
<h2 class="anchored" data-anchor-id="computational-complexity">Computational complexity</h2>
<ul>
<li><p>The solution via Cholesky factorization is a <span class="blue">fast direct approach</span> for finding <span class="math inline">\hat{\beta}</span>.</p></li>
<li><p>The expensive steps are:</p>
<ul>
<li>The formation of the matrix <span class="math inline">\bm{X}^T\bm{X}</span> requires <span class="math inline">\sim n p^2</span> elementary operations</li>
<li>The Cholesky factorization of <span class="math inline">\bm{X}^T\bm{X}</span> requires <span class="math inline">\sim p^3 / 3</span> elementary operations.</li>
</ul></li>
</ul>
<div class="incremental">
<ul>
<li><p>This gives an overall computational complexity of order <span class="math display">
\sim n p^2 + p^3 /3,
</span> which corrects the typographical error of the A&amp;S textbook.</p></li>
<li><p>This means that in <span class="orange">high-dimensional</span> settings (large <span class="math inline">p</span>) computations become rapidly <span class="orange">very costly</span>, being cubic in <span class="math inline">p</span>.</p></li>
</ul>
</div>
</section>
<section id="error-propagation-in-normal-equations" class="level2">
<h2 class="anchored" data-anchor-id="error-propagation-in-normal-equations">Error propagation in normal equations</h2>
<ul>
<li>The normal equations method is typically <span class="blue">quicker</span> than other algorithms, as it removes the dependency on <span class="math inline">n</span>, but it is in general numerically more <span class="orange">unstable</span>.</li>
</ul>
<div class="incremental">
<ul>
<li><p>Consider for example the following matrix: <span class="math display">
\bm{X} = \begin{bmatrix}1 &amp; 1 \\
\epsilon &amp; 0 \\
0 &amp; \epsilon \end{bmatrix},
</span> for a small value <span class="math inline">\epsilon &gt; 0</span>. Then, we obtain that <span class="math display">\bm{X}^T \bm{X} = \begin{bmatrix}1 + \epsilon^2&amp; 1 \\
1 &amp; 1 + \epsilon^2 \end{bmatrix}.
</span></p></li>
<li><p>The numerical computation of <span class="math inline">\epsilon^2</span> in <span class="math inline">\bm{X}^T\bm{X}</span> requires a higher precision compared to <span class="math inline">\epsilon</span>, leading to numerical instabilities and/or a <span class="orange">loss in accuracy</span>.</p></li>
</ul>
</div>
</section>
<section id="condition-numbers-and-normal-equations" class="level2">
<h2 class="anchored" data-anchor-id="condition-numbers-and-normal-equations">Condition numbers and normal equations</h2>
<ul>
<li><p>Suppose <span class="math inline">\bm{X} \in \mathbb{R}^{n \times p}</span> with <span class="math inline">n \ge p</span> has full rank and singular values <span class="math inline">d_1 \ge d_2 \ge \dots \ge d_p</span>. Then its <span class="orange">condition number</span> is <span class="math display">
\kappa(\bm{X}) = ||\bm{X}|| \cdot ||\bm{X}^+|| = \frac{d_1}{d_p},
</span> where <span class="math inline">\bm{X}^+</span> is the Moore-Penrose pseudo-inverse. Note that <span class="math inline">\kappa(\bm{X}) \ge 1</span>.</p></li>
<li><p>If <span class="math inline">\kappa(\bm{X})</span> is small, the matrix <span class="math inline">\bm{X}</span> is <span class="blue">well-conditioned</span>. Otherwise, it is <span class="orange">ill-conditioned</span>.</p></li>
<li><p>The condition number determines how accurately we can solve linear systems.</p></li>
<li><p>An important fact is: <span class="math display">
\kappa(\bm{X}^T\bm{X}) = \kappa(\bm{X})^2,
</span> implying that there is a clear loss of numerical accuracy when using normal equations.</p></li>
</ul>
</section>
<section id="the-qr-decomposition" class="level2">
<h2 class="anchored" data-anchor-id="the-qr-decomposition">The QR decomposition</h2>
</section>
</section>
<section id="iterative-methods" class="level1">
<h1>Iterative methods</h1>
</section>
<section id="generalized-linear-models" class="level1">
<h1>Generalized linear models</h1>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



<script src="un_A1_files/libs/quarto-html/zenscroll-min.js"></script>
</body></html>